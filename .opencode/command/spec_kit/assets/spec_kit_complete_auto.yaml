# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SMART SPECKIT: COMPLETE WORKFLOW (AUTONOMOUS MODE)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
role: Expert Developer using Smart SpecKit autonomously
purpose: Spec-driven development with mandatory compliance and autonomous execution
action: Run full SpecKit from spec to implementation with continuous validation

operating_mode:
  workflow: sequential_14_step
  workflow_compliance: MANDATORY
  workflow_execution: autonomous
  approvals: none
  tracking: progressive_task_checklists
  validation: continuous_self_validation
  description: |
    Executes the 14-step workflow without step-by-step approval.
    Supports optional chained workflows:
    - :with-research - Run research phase before planning
    - :auto-debug - Auto-dispatch debug agent on 3+ failures

    Checkpoints still pause for confirmation after optional workflows complete.

development_philosophy:
  principle: "Quality first, velocity second"
  approach: "Complete lifecycle with validated checkpoints"
  mandate: "Plan thoroughly, implement carefully, verify continuously, execute autonomously"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OPTIONAL CHAINED WORKFLOWS CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
optional_workflows:
  research_integration:
    enabled: true
    trigger:
      flag: ":with-research"
      smart_detect: true
      uncertainty_threshold: 60 # Suggest if confidence < 60%
    insert_point: "after_phase_2"
    workflow_reference: "spec_kit_research_auto.yaml"
    checkpoint:
      enabled: true
      prompt: |
        ðŸ“ WORKFLOW CHECKPOINT - Research Complete

        âœ… Research phase complete
        Created: research.md (17 sections)

        Continue to Step 1 (Request Analysis)? [Y/n/review]
      options:
      - key: "Y"
        action: "continue"
        description: "Continue to main workflow"
      - key: "n"
        action: "pause"
        description: "Pause workflow here"
      - key: "review"
        action: "show_output"
        description: "Review research.md before continuing"

  debug_integration:
    enabled: true
    trigger:
      flag: ":auto-debug"
      auto_suggest: true
      failure_threshold: 3 # Suggest after 3+ failures
    within_step: 10
    workflow_reference: "../../debug.md" # Uses debug command logic
    checkpoint:
      enabled: true
      prompt: |
        ðŸ“ WORKFLOW CHECKPOINT - Debug Complete

        âœ… Debug delegation complete
        Root Cause: {root_cause}
        Fix: {fix_status}

        Continue with Step 10? [Y/n/review]
      options:
      - key: "Y"
        action: "retry_task"
        description: "Retry task with fix applied"
      - key: "n"
        action: "pause"
        description: "Pause workflow here"
      - key: "review"
        action: "show_debug_report"
        description: "Review debug findings"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# USER INPUTS (Transformed from raw text)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user_inputs:
  spec_folder: |
    [SPEC_FOLDER]

    Spec folder path (e.g., specs/001 or specs/001-feature-name).
    Leave empty to auto-create next available spec number.

  context: |
    [CONTEXT]

    Provide background information, constraints, or existing documentation
    that should inform the development. Examples:
    - Environment details (staging/production URLs)
    - Current state of related features
    - Technical stack and dependencies
    - Known constraints or limitations
    Leave empty to infer from REQUEST and environment exploration.

  issues: |
    [ISSUES]

    List known issues, problems, or concerns that need to be addressed.
    Examples:
    - Bug reports or error messages
    - Performance concerns
    - User feedback or complaints
    - Technical debt to address
    Leave empty to discover during analysis.

  request: |
    [REQUEST]

    Describe the complete work to be done. Be specific about:
    - What needs to be built or changed
    - The problem to solve
    - Goals and objectives
    - Success criteria
    - Any specific requirements

  environment: |
    [STAGING LINK]

    Staging or production URL for browser testing. Leave empty to skip
    browser-based verification steps.

  scope: |
    [FILES]

    Files or folders to work with. Can be:
    - Single file path
    - Multiple paths (one per line)
    - Glob patterns (e.g., src/**/*.js)
    - Leave empty to use default scope (specs/**)

  worker_model: |
    [WORKER_MODEL]

    Model to use for parallel worker agents (if multi-agent dispatch selected).
    Options: opus | gemini | gpt
    Default: opus
    Leave empty to use default opus model.

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FIELD HANDLING
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
field_handling:
  spec_id:
    derive_from: "spec_folder path using pattern specs/{NNN} or specs/{NNN-name}"
    fallback: "Extract numeric portion or use timestamp if extraction fails"

  defaults:
    spec_folder_empty: "Auto-create specs/{NNN} from highest +001"
    context_empty: "Infer from [REQUEST], [STAGING LINK], and codebase exploration"
    issues_empty: "Investigate and discover during workflow"
    environment_empty: "Skip browser testing steps"
    scope_empty: "Use scope_policy.default"

  scope_policy:
    default: "specs/**"
    rule: "Limit file operations to scope when provided"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DOCUMENTATION LEVELS (Progressive Enhancement)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
documentation_levels:
  level_1_baseline:
    name: "Level 1 (Baseline)"
    required_files:
    - spec.md
    - plan.md
    - tasks.md
    loc_guidance: "<100 LOC"
    use_case: "Simple changes, bug fixes, minor features"

  level_2_verification:
    name: "Level 2 (Verification)"
    required_files:
    - spec.md
    - plan.md
    - tasks.md
    - checklist.md
    loc_guidance: "100-499 LOC"
    use_case: "Medium features, refactoring, multi-file changes"

  level_3_full:
    name: "Level 3 (Full)"
    required_files:
    - spec.md
    - plan.md
    - tasks.md
    - checklist.md
    - decision-record.md
    loc_guidance: ">=500 LOC"
    use_case: "Complex features, architecture changes, high-risk modifications"

  level_selection:
    note: "LOC thresholds are SOFT GUIDANCE - choose level based on complexity and risk"
    default: "Level 1 for simple tasks, escalate based on analysis"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AVAILABLE TEMPLATES (Level-Specific)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
available_templates:
  # Default level when not explicitly specified
  default_level: level_2

  # Level 1 - Baseline (<100 LOC)
  level_1:
    spec: .opencode/skill/system-spec-kit/templates/level_1/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_1/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_1/tasks.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_1/implementation-summary.md

  # Level 2 - Verification (100-499 LOC)
  level_2:
    spec: .opencode/skill/system-spec-kit/templates/level_2/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_2/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_2/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_2/checklist.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_2/implementation-summary.md

  # Level 3 - Full (>=500 LOC)
  level_3:
    spec: .opencode/skill/system-spec-kit/templates/level_3/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_3/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_3/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_3/checklist.md
    decision_record: .opencode/skill/system-spec-kit/templates/level_3/decision-record.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_3/implementation-summary.md

  # Level 3+ - Extended (Complex/Enterprise)
  level_3_plus:
    spec: .opencode/skill/system-spec-kit/templates/level_3+/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_3+/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_3+/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_3+/checklist.md
    decision_record: .opencode/skill/system-spec-kit/templates/level_3+/decision-record.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_3+/implementation-summary.md

  # Shared templates (available at any level)
  shared:
    research: .opencode/skill/system-spec-kit/templates/research.md
    handover: .opencode/skill/system-spec-kit/templates/handover.md
    debug_delegation: .opencode/skill/system-spec-kit/templates/debug-delegation.md

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PARALLEL DISPATCH CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Smart parallel sub-agent dispatch for eligible workflow phases.
# Uses 5-dimension complexity scoring algorithm.
# Always ask before parallel dispatch (no auto-dispatch)
# Exception: Step 6 Planning exploration is automatic (core planning feature)
parallel_dispatch_config:
  enabled: true

  # Complexity scoring algorithm (5 dimensions, weighted)
  complexity_scoring:
    domain_count:
      weight: 0.35
      domains: [ code, analysis, docs, git, testing, devops ]
      scoring: "1=0.0, 2=0.5, 3+=1.0"
    file_count:
      weight: 0.25
      scoring: "1-2=0.0, 3-5=0.5, 6+=1.0"
    loc_estimate:
      weight: 0.15
      scoring: "<50=0.0, 50-200=0.5, >200=1.0"
    parallel_opportunity:
      weight: 0.20
      scoring: "sequential=0.0, some=0.5, high=1.0"
    task_type:
      weight: 0.05
      scoring: "trivial=0.0, moderate=0.5, complex=1.0"

  # Decision thresholds (no auto-dispatch)
  thresholds:
    direct_max: 20
    ask_min: 20
    min_domains_for_ask: 2
    # NOTE: No auto-dispatch - always ask before parallel dispatch
    # Always ask user before parallel dispatch (except Step 6 Planning)

    # Session preference (1 hour persistence)
  session_preference:
    persist_duration_seconds: 3600

  # Override phrases for power users
  override_phrases:
    direct: [ "proceed directly", "handle directly", "skip parallel", "skip agents" ]
    parallel: [ "use parallel", "dispatch agents", "parallelize", "use agents" ]
    auto: [ "auto-decide", "auto mode", "decide for me" ]

  # Question template for parallel dispatch
  question_template:
    method: present_options_to_user
    header: "Parallel Dispatch"
    format: |
      **Phase: {phase_name}**
      Complexity: {complexity_score}% | Domains: {domain_count} ({domains_list})

      This phase may benefit from parallel sub-agents for faster execution.
    options:
    - id: A
      label: "Handle directly"
      description: "Execute phase sequentially without parallel agents"
    - id: B
      label: "Use parallel agents"
      description: "Dispatch specialized agents for faster parallel execution"
    - id: C
      label: "Auto-decide for session"
      description: "Let system decide based on complexity thresholds (1 hour)"

  # Eligible phases in this workflow
  eligible_phases:
  - step_3_specification
  - step_6_planning # Has inline_parallel_exploration - 4 agents dispatched directly
  - step_8_analysis
  - step_10_development

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MULTI-AGENT DISPATCH CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
multi_agent_config:
  enabled: true

  # Worker model configuration
  # User can override via worker_model input field
  worker_model_config:
    default: "opus"
    allowed: ["opus", "gemini", "gpt"]
    description: "Model for parallel worker agents"
    source: "[WORKER_MODEL] input or default"

  dispatch_modes:
    single:
      id: A
      label: "Single Agent"
      description: "Execute with one primary agent (default)"
      agent_count: 1
      model: "opus"

    multi_small:
      id: B
      label: "Multi-Agent (1+2)"
      description: "1 orchestrator + 2 parallel workers"
      orchestrator:
        model: "opus"
        role: "coordinator"
        responsibilities:
          - "Coordinate worker dispatch for exploration and analysis"
          - "Synthesize worker outputs into unified findings"
          - "Execute specification and planning steps"
          - "Create final documentation artifacts"
      workers:
        - model: "{worker_model|opus}"  # User-configurable, default: opus
          role: "architecture_explorer"
          focus: "Project Structure Analysis"
          step: 6
          responsibilities:
            - "Analyze project structure and entry points"
            - "Map component connections and dependencies"
            - "Identify architectural patterns"
            - "Document infrastructure layout"
        - model: "{worker_model|opus}"  # User-configurable, default: opus
          role: "feature_explorer"
          focus: "Feature Pattern Analysis"
          step: 6
          responsibilities:
            - "Find similar features in codebase"
            - "Identify related patterns and implementations"
            - "Map feature interdependencies"
            - "Document reusable components"

    multi_large:
      id: C
      label: "Multi-Agent (1+3)"
      description: "1 orchestrator + 3 parallel workers"
      orchestrator:
        model: "opus"
        role: "coordinator"
        responsibilities:
          - "Coordinate worker dispatch for exploration and analysis"
          - "Synthesize worker outputs into unified findings"
          - "Execute specification and planning steps"
          - "Create final documentation artifacts"
      workers:
        - model: "{worker_model|opus}"  # User-configurable, default: opus
          role: "architecture_explorer"
          focus: "Project Structure Analysis"
          step: 6
          responsibilities:
            - "Analyze project structure and entry points"
            - "Map component connections and dependencies"
            - "Identify architectural patterns"
            - "Document infrastructure layout"
        - model: "{worker_model|opus}"  # User-configurable, default: opus
          role: "feature_explorer"
          focus: "Feature Pattern Analysis"
          step: 6
          responsibilities:
            - "Find similar features in codebase"
            - "Identify related patterns and implementations"
            - "Map feature interdependencies"
            - "Document reusable components"
        - model: "{worker_model|opus}"  # User-configurable, default: opus
          role: "dependency_explorer"
          focus: "Dependency and Test Analysis"
          step: 6
          responsibilities:
            - "Map imports and module dependencies"
            - "Identify affected areas by proposed changes"
            - "Review test patterns and infrastructure"
            - "Document testing requirements"

  worker_output_format:
    structure:
      role: "string - worker role identifier"
      focus: "string - assigned focus area"
      findings: "array - key discoveries"
      evidence: "array - file paths and line references"
      recommendations: "array - actionable suggestions"
      confidence: "number - 0-100 confidence score"
    example: |
      {
        "role": "architecture_explorer",
        "focus": "Project Structure Analysis",
        "findings": [
          "Main entry point is src/index.ts",
          "Component architecture follows Webflow patterns"
        ],
        "evidence": [
          "src/index.ts:1-50 - initialization logic",
          "src/components/ - component directory"
        ],
        "recommendations": [
          "Follow existing component pattern for new feature",
          "Add initialization to main entry point"
        ],
        "confidence": 85
      }

  fallback_behavior:
    on_worker_timeout: "Continue with available outputs, note incomplete analysis"
    on_all_workers_fail: "Fall back to single-agent mode"
    on_orchestrator_fail: "Save partial results to scratch/"
    worker_timeout_seconds: 60

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AGENT ROUTING CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
agent_routing:
  # Phase 3 (Optional Research)
  research_phase:
    condition: ":with-research flag OR confidence < 60%"
    agent: "@research"
    agent_file: ".opencode/agent/research.md"
    dispatch_method: |
      Task tool with prompt:
      ---
      You are the @research agent. Execute your 9-step research workflow.
      
      Topic: {feature_description}
      Spec Folder: {spec_path}
      
      Execute your full workflow:
      - Step 1-2: Analysis and Pre-Work Review
      - Step 3-7: Investigation and Analysis
      - Step 8-9: Compilation and Context Save
      
      Return structured findings for research.md compilation.
      ---
    fallback: "general"
    fallback_reason: "If @research agent file unavailable or dispatch fails"
    on_fallback: |
      Warning: Research agent unavailable, using general dispatch.
      Research workflow will continue with standard Task execution.

  # Step 3 (Specification)
  specification_phase:
    step: 3
    agent: "@speckit"
    agent_file: ".opencode/agent/speckit.md"
    model: opus  # Default model - use opus ONLY if user explicitly requests
    dispatch_method: |
      Task tool with prompt:
      ---
      You are the @speckit agent. Create spec folder documentation.
      
      Feature: {feature_description}
      Level: {documentation_level}
      Folder: {spec_path}
      
      Create spec.md using template-first approach.
      Validate structure against templates.
      
      Return confirmation of created files.
      ---
    fallback: "general"
    fallback_reason: "If @speckit agent file unavailable or dispatch fails"
    on_fallback: |
      Warning: Speckit agent unavailable, using general dispatch.
      Specification will continue with standard Task execution.

  # Step 11 (Checklist Verification)
  verification_phase:
    step: 11
    agent: "@review"
    agent_file: ".opencode/agent/review.md"
    dispatch_method: |
      Task tool with prompt:
      ---
      You are the @review agent. Verify implementation completeness.
      
      Spec Folder: {spec_path}
      Checklist: {spec_path}/checklist.md
      
      Execute:
      1. Load checklist.md
      2. Verify ALL P0 items are [x] with evidence
      3. Verify ALL P1 items are [x] or have deferral approval
      4. Score against quality rubric (100-point scale)
      
      Return:
      - P0 status: [PASS/FAIL]
      - P1 status: [PASS/PARTIAL/FAIL]
      - Quality score: [0-100]
      - Blocking issues: [list]
      ---
    fallback: "general"
    fallback_reason: "If @review agent file unavailable or dispatch fails"
    blocking: true
    on_block: |
      â›” BLOCKED: P0 checklist items incomplete.
      Review agent found the following blocking issues:
      {blocking_issues}
      
      Address these P0 items before claiming completion.
    on_fallback: |
      Warning: Review agent unavailable, using general dispatch.
      Verification will continue with standard Task execution.

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# QUALITY GATES CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Quality gates ensure workflow integrity at critical transition points.
# Gates validate state before allowing progression.
quality_gates:
  enabled: true

  pre_execution:
    location: "Before Step 1"
    purpose: "Validate inputs and prerequisites"
    threshold: 60
    blocking: soft
    checks:
      - id: "feature_description"
        description: "Feature description is not empty"
        points: 30
      - id: "spec_path_valid"
        description: "Spec path is valid or can be created"
        points: 30
      - id: "execution_mode_set"
        description: "Execution mode is set (auto/confirm)"
        points: 20
      - id: "memory_context"
        description: "Memory context loaded (if applicable)"
        points: 20
    on_fail: |
      âš ï¸ Pre-execution gate score below threshold ({score}/100, need 60).
      Missing: {missing_checks}
      Proceeding with warning (soft block).

  planning_gate:
    location: "Between Step 7 and Step 8"
    purpose: "Verify planning artifacts complete before implementation"
    threshold: 70
    blocking: hard
    critical: true  # This is the most important gate
    checks:
      - id: "spec_exists"
        description: "spec.md exists in spec folder"
        points: 20
      - id: "spec_no_clarification"
        description: "spec.md has no [NEEDS CLARIFICATION] markers"
        points: 5
      - id: "plan_exists"
        description: "plan.md exists in spec folder"
        points: 20
      - id: "plan_has_approach"
        description: "plan.md has technical approach defined"
        points: 5
      - id: "tasks_exists"
        description: "tasks.md exists in spec folder"
        points: 20
      - id: "tasks_has_format"
        description: "tasks.md has T### formatted tasks"
        points: 5
      - id: "checklist_verified"
        description: "checklist.md items verified (Level 2+)"
        points: 15
      - id: "review_approval"
        description: "@review agent approval obtained"
        points: 10
    on_fail: |
      â›” PLANNING GATE BLOCKED (score: {score}/100, need 70)

      Missing artifacts:
      {missing_checks}

      WORKFLOW HALTED. Return to incomplete step and address issues.
      Use "force proceed" to bypass (not recommended).
    review_integration:
      dispatch: true
      agent: "@review"
      blocking: true
      on_review_fail: |
        â›” @review agent found blocking issues:
        {blocking_issues}

        Address P0 items before proceeding to implementation.

  post_execution:
    location: "After Step 12"
    purpose: "Verify all deliverables exist"
    threshold: 70
    blocking: hard
    checks:
      - id: "tasks_complete"
        description: "All tasks in tasks.md marked [x]"
        points: 30
      - id: "summary_exists"
        description: "implementation-summary.md exists"
        points: 25
      - id: "summary_sections"
        description: "implementation-summary.md has required sections"
        points: 15
      - id: "memory_saved"
        description: "memory/*.md context saved"
        points: 20
      - id: "validation_passed"
        description: "Validation script passed"
        points: 10
    on_fail: |
      â›” Post-execution gate score below threshold ({score}/100, need 70).
      Missing deliverables:
      {missing_checks}

      Complete missing items before claiming workflow done.

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CIRCUIT BREAKER CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Circuit breaker prevents cascading failures when agents fail repeatedly.
# Each agent has an independent circuit.
circuit_breaker:
  enabled: true

  # Global settings
  failure_threshold: 3          # Consecutive failures before OPEN
  recovery_timeout_ms: 60000    # Time in OPEN before HALF-OPEN (1 minute)
  success_threshold: 2          # Successes in HALF-OPEN to CLOSE
  monitoring_window_ms: 300000  # Window for failure counting (5 minutes)

  # States: CLOSED (normal), OPEN (failing), HALF_OPEN (testing)
  states:
    CLOSED:
      description: "Normal operation - requests pass through"
      behavior: "dispatch_to_agent"
    OPEN:
      description: "Agent failing - use fallback immediately"
      behavior: "use_fallback"
    HALF_OPEN:
      description: "Testing recovery - allow single request"
      behavior: "test_single_request"

  # Per-agent circuit tracking
  per_agent_tracking:
    research:
      agent: "@research"
      fallback: "general"
      initial_state: "CLOSED"
      preserve_on_fallback: []  # No special behavior preserved

    speckit:
      agent: "@speckit"
      fallback: "general"
      initial_state: "CLOSED"
      preserve_on_fallback: []  # No special behavior preserved

    review:
      agent: "@review"
      fallback: "general"
      initial_state: "CLOSED"
      preserve_on_fallback:
        - "blocking"  # CRITICAL: blocking behavior preserved even on fallback
      special_handling: |
        When @review circuit is OPEN:
        - Fall back to general agent
        - PRESERVE blocking: true behavior
        - General agent still performs P0/P1 verification
        - P0 failures still block workflow progression
        - Quality score threshold (70) still enforced

  # Recovery protocol
  recovery_protocol:
    on_dispatch: |
      IF circuit[agent].state == OPEN:
        IF time_since_last_failure > recovery_timeout_ms:
          SET circuit[agent].state = HALF_OPEN
          ALLOW single request
        ELSE:
          USE fallback
          LOG "Circuit OPEN for {agent}, using {fallback}"

      IF circuit[agent].state == HALF_OPEN:
        IF request succeeds:
          INCREMENT circuit[agent].success_count
          IF success_count >= success_threshold:
            SET circuit[agent].state = CLOSED
            RESET circuit[agent].failures = 0
        ELSE:
          SET circuit[agent].state = OPEN
          UPDATE circuit[agent].last_failure

    on_failure: |
      INCREMENT circuit[agent].failures
      IF failures >= failure_threshold:
        SET circuit[agent].state = OPEN
        UPDATE circuit[agent].last_failure
        LOG "Circuit OPENED for {agent}"

  # Logging
  logging:
    on_state_change: true
    on_fallback_used: true
    include_failure_details: true

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIDENCE & CLARIFICATION FRAMEWORK
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Core Principle: If not sure or confidence < 80%, pause and ask for clarification.
# Present a multiple-choice path forward.
confidence_framework:

  # Confidence thresholds and required actions
  thresholds:
    high:
      range: "80-100%"
      action: "Proceed with at least one citable source or strong evidence"
      behavior: "Execute step autonomously"
    medium:
      range: "40-79%"
      action: "Proceed with caution - provide caveats and counter-evidence"
      behavior: "Log uncertainty, continue with documented assumptions"
    low:
      range: "0-39%"
      action: "Ask for clarification with multiple-choice question or mark UNKNOWN"
      behavior: "STOP and present A/B/C options to user"
    safety_override:
      trigger: "Blocker or conflicting instruction detected"
      action: "Ask regardless of score"

  # Weighted scoring formula
  scoring_formula:
    frontend_weights:
      requirements_clarity: 0.25
      api_component_design: 0.15
      state_data_flow: 0.15
      type_safety_security: 0.10
      performance: 0.10
      accessibility_testing: 0.10
      tooling_risk: 0.15
    backend_weights:
      requirements_clarity: 0.25
      api_component_design: 0.20
      state_data_flow: 0.15
      type_safety_security: 0.15
      performance: 0.10
      accessibility_testing: 0.10
      tooling_risk: 0.05
    calculation: "Weighted sum of factor scores (0-1 each), rounded to whole percent"

  # Standard reply format for confidence checkpoints
  reply_format:
    required_fields:
    - "Confidence: NN%"
    - "Top factors: 2-3 bullets"
    - "Next action: proceed | proceed with caution | ask for clarification"
    conditional_fields:
      if_asking: "Include one multiple-choice question with A/B/C options"
      uncertainty: "Brief note of unknowns (or 'UNKNOWN' if data is missing)"
      sources: "Files/lines or URLs used (name evidence when relied upon)"
    optional_json_block:
      when: "Fact-checking required"
      format: |
        {
          "label": "TRUE | FALSE | UNKNOWN",
          "truth_score": 0.0-1.0,
          "uncertainty": 0.0-1.0,
          "citations": ["..."],
          "audit_hash": "sha256(...)"
        }

  # Clarification question format (for LOW confidence)
  clarification_format:
    template: |
      "I need clarity (confidence: [NN%]). Which approach:
      - A) [option with brief rationale]
      - B) [option with brief rationale]
      - C) [option with brief rationale]"
    rules:
    - "Maximum 3 options"
    - "Each option must have brief rationale"
    - "Options must be mutually exclusive"
    - "Include 'other' only if genuinely applicable"

  # Escalation rules
  escalation:
    timebox_minutes: 10
    failed_attempts_threshold: 2
    action: "Pause and ask clarifying question with 2-3 concrete options"
    blocker_escalation:
      trigger: "Blockers beyond control (access, missing data)"
      action: "Escalate with current evidence, UNKNOWNs, and proposed next step"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# REQUEST ANALYSIS & SOLUTION FRAMEWORK
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Before ANY action or file changes, work through these phases.
request_analysis_framework:

  # Solution flow overview
  solution_flow:
    steps:
    - "Request Received â†’ Parse carefully: What is ACTUALLY requested?"
    - "Gather Context â†’ Read files, check skills folder"
    - "Identify Approach â†’ What's the SIMPLEST solution that works?"
    - "Validate Choice â†’ Does this follow patterns? Is it maintainable?"
    - "Clarify If Needed â†’ If ambiguous or <80% confidence: ask"
    - "Scope Check â†’ Am I solving ONLY what was asked?"
    - "Execute â†’ Implement with minimal complexity"

  # Pre-action analysis checklist
  analysis_checklist:
    request_analysis:
    - "Actual request: [Restate in own words]"
    - "Desired outcome: [Be specific]"
    - "Scope: [Single change | Feature | Investigation]"
    - "Doc level: [1: <100 LOC | 2: 100-499 LOC | 3: >=500 LOC]"
    context:
    - "Files to read/modify?"
    - "Patterns to follow?"
    - "What's working/broken?"
    - "MINIMUM needed? (avoid over-engineering)"

  # Core design principles
  design_principles:
    simplicity_first:
      name: "KISS"
      rules:
      - "Use existing patterns; justify new abstractions"
      - "Direct solution > clever complexity"
      - "Every abstraction must earn its existence"
    evidence_based:
      name: "Evidence-Based with Citations"
      rules:
      - "Cite sources (file paths + line ranges) or state 'UNKNOWN'"
      - "Format: [SOURCE: file.md:lines] or [CITATION: NONE]"
      - "High-stakes decisions: Require >=1 primary source or escalate"
    effectiveness:
      name: "Effectiveness Over Elegance"
      rules:
      - "Performant + Maintainable + Concise + Clear"
      - "Obviously correct approach > clever tricks"
      - "Scope discipline: Solve ONLY stated problem, no gold-plating"

  # Pre-change validation checklist
  pre_change_validation:
    items:
    - "Simplest solution? (no unneeded abstractions, existing patterns)"
    - "Scope discipline? (ONLY stated problem, no feature creep)"
    - "Spec folder created? (required files for level)"
    - "Read files first? (understand before modify)"
    - "Clear success criteria?"
    - "Confidence >=80%? (if not: ask clarifying question)"
    - "Sources cited? (or 'UNKNOWN')"
    - "User approval received?"
    - "If Level 2+: checklist.md items verified"
    verification_loop: "Sense â†’ Interpret â†’ Verify â†’ Reflect â†’ Publish"
    stop_conditions:
    - "Any item unchecked"
    - "No spec folder"
    - "No user approval"
    stop_action: "STOP and address before proceeding"

  # Final output review
  final_review:
    verification_summary:
      required_for: "Factual content"
      parts:
      - "EVIDENCE SUPPORTS: List top 1-3 supporting sources/facts"
      - "EVIDENCE CONTRADICTS/LIMITS: List any contradictions or limitations"
      - "CONFIDENCE: Rate 0-100% + label (LOW/MED/HIGH) with brief justification"
    final_checklist:
    - "Claims with confidence <40% (LOW) â†’ Flag explicitly or convert to 'UNKNOWN'"
    - "Unverified sources â†’ Mark [STATUS: UNVERIFIED]"
    - "Missing counter-evidence for significant claims â†’ Add caveats"
    number_handling:
      rule: "Prefer ranges or orders of magnitude unless confidence >=80% and source cited"
      qualifiers: [ "approximately", "range of", "circa" ]
      prohibition: "Never fabricate specific statistics to appear precise"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# WORKFLOW ENFORCEMENT (CRITICAL)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
workflow_enforcement:
  mode: strict
  step_order: sequential_mandatory
  skip_allowed: false

  phase_gate:
    location: "Between Step 7 and Step 8"
    purpose: "Verify planning complete before implementation"
    requirements:
    - "spec.md exists and has no [NEEDS CLARIFICATION] markers"
    - "plan.md exists with technical approach"
    - "tasks.md exists with all tasks listed"
    action_if_failed: "STOP and return to incomplete step"

  step_completion_rule: |
    FOR EACH STEP:
    1. Execute ALL activities listed
    2. Verify ALL outputs exist
    3. Mark step âœ… in tracking table (complete.md)
    4. ONLY THEN proceed to next step

    â›” NEVER skip a step
    â›” NEVER proceed without marking previous step complete
    â›” NEVER jump to implementation code before Step 8

  critical_steps:
    step_10_development:
      enforcement: "MUST mark tasks [x] in tasks.md as completed"
      verification: "Count [x] vs [ ] - all must be [x]"
    step_11_checklist_verify:
      enforcement: "MUST verify all P0/P1 checklist items (Level 2+)"
      verification: "All P0 items [x], P1 either [x] or deferred with approval"
    step_12_completion:
      enforcement: "MUST create implementation-summary.md"
      verification: "File must exist in spec folder"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONTEXT LOADING (START OF WORKFLOW)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
context_loading:
  trigger: "At workflow START, before Step 1"
  purpose: "Load prior context for informed decision-making"

  mcp_integration:
    tool: memory_search
    note: "Call MCP tools directly - NEVER through Code Mode"
    parameters:
      query: "context for {spec_folder_name}"
      specFolder: "{spec_folder_path}"
      anchors: ['summary', 'decisions', 'state']
    example: |
      memory_search({
        query: "prior context and decisions",
        specFolder: "specs/007-feature-name",
        anchors: ['summary', 'decisions', 'state']
      })

  command_reference: "/memory:context"
  when_to_skip:
    - "New spec folder (no prior context exists)"
    - "User explicitly says 'skip context' or 'fresh start'"

  behavior:
    if_context_found: "Surface relevant decisions and state before proceeding"
    if_no_context: "Proceed to Step 1 without delay"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# WORKFLOW (14 STEPS - ALL LOGIC ABSORBED)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
workflow:
  step_1_request_analysis:
    purpose: Analyze inputs and define development scope
    input_source: USER_INPUTS_SECTION_ABOVE
    spec_folder: "[SPEC_FOLDER] â†’ auto-create if empty"
    context: "[CONTEXT] â†’ infer if empty"
    issues: "[ISSUES] â†’ discover if empty"
    request: "[REQUEST] â†’ REQUIRED"
    environment: "[STAGING LINK] â†’ skip browser testing if empty"
    scope: "[FILES] â†’ default scope if empty"
    activities:
    - Analyze all user inputs thoroughly
    - Define development scope for the spec folder
    - Verify or create spec folder structure
    - Check for existing artifacts
    - Establish development scope
    deep_analysis:
      focus: comprehensive_requirement_analysis
      approach: thorough_investigation
      outputs:
      - requirement_summary
      - approach_overview
      - complexity_assessment
      - key_objectives
      - success_criteria
      - investigation_priorities
      - technical_depth_required
      - output_structure_planning

    # CONFIDENCE CHECKPOINT
    confidence_checkpoint:
      evaluate_at: "After analyzing all inputs"
      scoring_factors:
      - factor: "Requirements clarity"
        weight: 0.40
        assess: "Is the request unambiguous? Are goals clear?"
      - factor: "Scope definition"
        weight: 0.30
        assess: "Is scope well-bounded? Are constraints identified?"
      - factor: "Context availability"
        weight: 0.30
        assess: "Is sufficient context provided or discoverable?"
      thresholds:
        high_80_plus:
          action: "Proceed to Step 2"
          log: "Confidence: [NN%] - Requirements clear, proceeding"
        medium_40_79:
          action: "Proceed with caution"
          log: "Confidence: [NN%] - [uncertainty notes] - proceeding with assumptions documented"
          requirement: "Document assumptions in spec.md Assumptions section"
        low_below_40:
          action: "STOP - Ask clarification"
          format: |
            "I need clarity (confidence: [NN%]). Please clarify:
            - A) [first interpretation with rationale]
            - B) [second interpretation with rationale]
            - C) [third interpretation with rationale]"
          wait_for: "User response before proceeding"

    validation: understanding_confirmed

  step_2_pre_work_review:
    purpose: Review skills folder and project standards
    activities:
    - Read and review AGENTS.md (project principles)
    - Check skills folder (.opencode/skill/) for relevant coding standards
    - Extract coding standards summary
    - Identify architectural patterns
    - Document project conventions
    - Identify constraints
    - Verify principle alignment
    - Initialize or update project constitution if needed
    required_documents:
    - AGENTS.md
    - Skills folder (if available)
    verification: MUST_REVIEW
    deep_analysis:
      focus: skill_alignment
      approach: systematic_review
      outputs:
      - coding_standards_summary
      - architectural_patterns
      - project_conventions
      - constraint_identification
      - principle_alignment
    validation: principles_established

  # â”€â”€ RESEARCH TRIGGER CHECK (after Step 2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  phase_3_research:
    condition: |
      research_triggered = FALSE

      IF ":with-research" in command_flags:
        research_triggered = TRUE
        trigger_reason = "explicit_flag"
      ELSE IF confidence_score < 60:
        # In AUTONOMOUS mode with smart-detect, auto-trigger research
        research_triggered = TRUE
        trigger_reason = "uncertainty_auto_detected"

    actions:
      if_triggered:
      - log: "ðŸ“š Initiating research phase (reason: {trigger_reason})"
      - execute_workflow: "spec_kit_research_auto.yaml"
      - on_complete: "show_checkpoint"
      if_skipped:
      - log: "Research phase skipped (confidence: {confidence_score}%)"
      - continue_to: "step_3"

  step_3_specification:
    purpose: Create comprehensive feature specification

    # PRE-PHASE: Smart parallel dispatch check
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [ code, docs ]
      complexity_boost: 0
      decision_logic: |
        BEFORE starting this phase, evaluate parallel dispatch:
        1. Check for override phrases in user request
        2. Check for session preference (from previous "Auto-decide" selection)
        3. Check for sequential dependencies (skip if detected)
        4. Calculate phase complexity using parallel_dispatch_config
        5. Apply thresholds:
           - <20% â†’ proceed directly (no parallel agents)
           - â‰¥20% + 2 domains â†’ ALWAYS ask user
           NOTE: No auto-dispatch - always ask before parallel dispatch
      on_parallel_dispatch:
        agents:
        - name: "spec_explorer"
          focus: "Existing specifications and patterns in codebase"
          model: "{worker_model|opus}"
        - name: "requirement_analyzer"
          focus: "Similar features and their requirements"
          model: "{worker_model|opus}"
        dispatch_note: "Spawn agents in SINGLE message for parallel execution"
      fallback: "Proceed with activities below if dispatch fails or user chooses direct"

    activities:
    - Find highest feature number across all sources
    - Run create-spec-folder.sh script with calculated number
    - Estimate complexity and select documentation level using progressive enhancement:
      - "Level 1 (Baseline): <100 LOC - spec.md + plan.md + tasks.md"
      - "Level 2 (Verification): 100-499 LOC - Level 1 + checklist.md"
      - "Level 3 (Full): >=500 LOC - Level 2 + decision-record.md"
    - Load spec.md and use as EXACT structure
    - Parse user description and extract key concepts
    - Identify actors, actions, data, constraints
    - Make informed guesses based on context for unclear aspects
    - Fill User Scenarios & Testing section
    - Generate Functional Requirements (testable)
    - Define Success Criteria (measurable, technology-agnostic)
    - Identify Key Entities if data involved
    - For Level 2+, include mandatory checklist.md with:
      - Requirement completeness checks
      - Feature readiness checks
    - For Level 3, include decision-record.md with:
      - Traceability Mapping (User Stories -> FRs)
      - Risk Matrix (minimum 2 risks)
      - Rollback Plan
      - Constitution Check in Assumptions
    # CONFIDENCE CHECKPOINT
    confidence_checkpoint:
      evaluate_at: "After drafting spec.md content"
      scoring_factors:
      - factor: "Requirements completeness"
        weight: 0.35
        assess: "Are all functional requirements identified and testable?"
      - factor: "Acceptance criteria clarity"
        weight: 0.35
        assess: "Are success criteria measurable and unambiguous?"
      - factor: "Technical feasibility"
        weight: 0.30
        assess: "Is the approach technically sound? Dependencies identified?"
      thresholds:
        high_80_plus:
          action: "Finalize spec.md and proceed to Step 4"
          log: "Confidence: [NN%] - Specification complete"
        medium_40_79:
          action: "Add [NEEDS CLARIFICATION] markers to uncertain sections"
          log: "Confidence: [NN%] - Proceeding with marked uncertainties"
          requirement: "Mark uncertain sections for Step 4 resolution"
        low_below_40:
          action: "STOP - Ask clarification before finalizing spec"
          format: |
            "Specification confidence low ([NN%]). Need clarity on:
            - A) [critical ambiguity 1 with options]
            - B) [critical ambiguity 2 with options]
            - C) [suggest research spike if technical uncertainty]"
          wait_for: "User response before finalizing spec.md"
      citation_requirement: |
        All technical decisions must cite sources:
        - Format: [SOURCE: file.md:lines] for code patterns
        - Format: [CITATION: URL] for external references
        - Use [CITATION: NONE] if based on general knowledge

    outputs:
    - spec.md: acceptance_criteria
    - location: "[SPEC_FOLDER]/spec.md"
    optional_documents:
    - decision-record-[name].md: "Architecture Decision Records"
    template: .opencode/skill/system-spec-kit/templates/level_2/spec.md  # Use level from available_templates based on complexity
    deep_analysis:
      focus: comprehensive_specification
      approach: rigorous_requirements_definition
      outputs:
      - feature_scope_definition
      - acceptance_criteria
      - technical_constraints
      - dependency_identification
      - edge_case_analysis
      - success_metrics
    validation: spec_complete

  step_4_clarification:
    purpose: Resolve ambiguities and clarify requirements
    activities:
    - Extract all [NEEDS CLARIFICATION] markers from spec
    - Limit to maximum 3 clarifications (prioritize by impact)
    - Make informed guesses for lower-priority items
    - For each clarification, research codebase for patterns
    - Test in browser when staging URL provided for live analysis
    - Resolve ambiguities through systematic investigation
    - Update spec.md with resolved clarifications
    - Document all assumptions made
    - Identify any remaining risks
    outputs:
    - resolved_ambiguities
    - clarified_requirements
    - updated_spec
    deep_analysis:
      focus: ambiguity_resolution
      approach: systematic_clarification
      outputs:
      - requirement_refinement
      - constraint_validation
      - assumption_documentation
      - risk_identification
    validation: requirements_clear

  step_5_quality_checklist:
    purpose: Generate validation checklist AND USE FOR ACTIVE VERIFICATION (Level 2+ requirement)
    level_requirement: "Level 2+ (Verification and Full)"
    activities:
    - Check documentation level - skip for Level 1, MANDATORY for Level 2+
    - Load checklist.md template
    - Generate domain-specific validation items with priorities (P0/P1/P2)
    - Create checklist file at FEATURE_DIR/checklist.md
    - Include content quality checks
    - Include requirement completeness checks
    - Include feature readiness checks
    - FOR EACH ITEM:
      - Verify condition is met
      - Mark as [x] with evidence link
      - If not met: document blocker (P0/P1) or deferral reason (P2)
    - Ensure ALL P0 items are complete (HARD BLOCKER)
    - Ensure ALL P1 items are complete or user-approved deferral
    - Document P2 deferrals with reasons
    - Update checklist.md file with verification marks
    verification_protocol:
      p0_handling: "BLOCKER - Cannot proceed without completion"
      p1_handling: "Required - Complete or get user approval to defer"
      p2_handling: "Optional - Can defer with documented reason"
    outputs:
    - quality_checklist: generated
    - location: "[SPEC_FOLDER]/checklist.md"
    - checklist_status: pass_or_fail
    - verified_items_count: "X/Y items verified"
    - p0_status: "all_complete or blocked"
    - deferred_items: list_of_deferred_p2_items
    template: .opencode/skill/system-spec-kit/templates/level_2/checklist.md  # Use level from available_templates based on complexity
    deep_analysis:
      focus: quality_validation_preparation
      approach: comprehensive_checklist_design
      outputs:
      - validation_criteria
      - testing_requirements
      - quality_gates
    validation: checklist_verified_and_marked

  step_6_planning:
    purpose: Create technical plan with implementation approach

    # â”€â”€ CODEBASE EXPLORATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Tool selection delegated to AGENTS.md Section 8 - no duplication here
    # - Lexical search (Grep): exact text patterns
    # - File discovery (Glob): find files by pattern
    # - Content reading (Read): examine file contents

    # INLINE 4-AGENT PARALLEL EXPLORATION
    # Self-contained exploration - no external skill dependency
    parallel_dispatch_note: |
      This phase dispatches 4 parallel agents directly via Task tool.
      Agents: Architecture Explorer, Feature Explorer, Dependency Explorer, Test Explorer.
      No additional question is asked because parallel dispatch is integral to this phase.

    # 4-Agent Parallel Exploration Configuration
    inline_parallel_exploration:
      description: "4-agent parallel exploration for verified planning"
      purpose: "Spawn 4 Explore agents to discover codebase patterns before planning"

      execution:
        tool: Task
        subagent_type: explore
        model: opus # Fast, cost-effective exploration
        parallel: true # All 4 agents spawn in single message

      agents:
        architecture_explorer:
          focus: "Project structure, entry points, component connections"
          purpose: "Understand system architecture"
          prompt: |
            Explore the codebase to find how the system architecture works for: {task_description}

            Return:
            1. Your hypothesis about the architecture
            2. Full paths to all relevant files (e.g., /path/to/file.ts:lineNumber)
            3. Any patterns you noticed (component structure, module organization, etc.)

            Do NOT draw conclusions - just report findings. The main agent will verify.

        feature_explorer:
          focus: "Similar features, related patterns"
          purpose: "Find reusable patterns"
          prompt: |
            Explore the codebase to find similar features or related patterns for: {task_description}

            Return:
            1. Your hypothesis about existing similar features
            2. Full paths to all relevant files
            3. Any patterns you noticed (naming conventions, implementation patterns, etc.)

            Do NOT draw conclusions - just report findings.

        dependency_explorer:
          focus: "Imports, modules, affected areas"
          purpose: "Identify integration points"
          prompt: |
            Explore the codebase to find dependencies and integration points for: {task_description}

            Return:
            1. Your hypothesis about which modules/files will be affected
            2. Full paths to all relevant files
            3. Any patterns you noticed (dependency chains, coupling points, etc.)

            Do NOT draw conclusions - just report findings.

        test_explorer:
          focus: "Test patterns, testing infrastructure"
          purpose: "Understand verification approach"
          prompt: |
            Explore the codebase to find test patterns and testing infrastructure.

            Return:
            1. Your hypothesis about how testing works in this project
            2. Full paths to all relevant test files
            3. Any patterns you noticed (test frameworks, mocking patterns, coverage expectations, etc.)

            Do NOT draw conclusions - just report findings.

      verification:
        description: "After agents return, verify hypotheses by reading identified files"
        approach:
        - "Read each file identified by Explore agents"
        - "Verify or refute each hypothesis"
        - "Cross-reference findings across agents for consistency"
        - "Build complete mental model of architecture, affected components, integration points, risks"
        - "Resolve conflicting hypotheses by reading additional files"

      outputs:
      - architecture_findings
      - feature_findings
      - dependency_findings
      - test_findings
      - verified_mental_model

      fallback:
        on_failure: "Use inline planning activities below"
        reason: "Graceful degradation if agents unavailable"

    # FALLBACK: Inline planning if exploration fails
    activities:
    - Run check-prerequisites.sh --json --paths-only to get feature paths
    - Load FEATURE_SPEC and AGENTS.md
    - Load plan.md and preserve exact structure
    - Fill Technical Context (mark unknowns as NEEDS CLARIFICATION)
    - Fill Constitution Check section
    - Evaluate gates (ERROR if violations unjustified)
    - Phase 0: Generate research.md to resolve all unknowns
    - Phase 1: Define component structure and interfaces
    - Generate Testing Strategy with test pyramid
    - Generate Success Metrics from spec criteria
    - Import Risk Matrix from spec
    - Generate Dependencies Tables
    - Generate Communication & Review sections
    - Re-evaluate Constitution Check post-design
    - Generate Phase 2-4 outlines (implementation phases)
    outputs:
    - plan.md: technical_approach
    - research.md: resolved_unknowns
    - dependencies: identified
    - upstream_docs: reviewed
    level_1_baseline:
    - spec.md: "Feature specification"
    - plan.md: "Technical approach"
    - tasks.md: "Implementation task breakdown"
    level_2_verification:
    - checklist.md: "Validation checklists (required at Level 2+)"
    level_3_full:
    - decision-record.md: "Architecture Decision Records (required at Level 3)"
    decision_records:
      when: significant_technical_decision_needs_documentation
      template: .opencode/skill/system-spec-kit/templates/level_3/decision-record.md  # Level 3+ only
      note: "Document architecture decisions with full context"
    template: .opencode/skill/system-spec-kit/templates/level_2/plan.md  # Use level from available_templates based on complexity

    # CONFIDENCE CHECKPOINT
    confidence_checkpoint:
      evaluate_at: "After drafting plan.md content"
      scoring_factors:
      - factor: "Technical approach clarity"
        weight: 0.30
        assess: "Is the implementation strategy well-defined?"
      - factor: "Risk identification"
        weight: 0.25
        assess: "Are risks identified with mitigation strategies?"
      - factor: "Dependency mapping"
        weight: 0.25
        assess: "Are all dependencies and integration points documented?"
      - factor: "Existing pattern alignment"
        weight: 0.20
        assess: "Does approach follow existing codebase patterns?"
      thresholds:
        high_80_plus:
          action: "Finalize plan.md and proceed to Step 7"
          log: "Confidence: [NN%] - Technical plan complete"
          cite: "Document key sources in plan.md Technical Context"
        medium_40_79:
          action: "Proceed but flag uncertainties"
          log: "Confidence: [NN%] - Plan has noted uncertainties"
          requirement: "Add RISK markers for uncertain technical decisions"
        low_below_40:
          action: "STOP - Request research spike or clarification"
          format: |
            "Technical planning confidence low ([NN%]). Options:
            - A) Research spike: [specific technical question to investigate]
            - B) Simplify scope: [reduce to well-understood approach]
            - C) Clarify requirements: [specific question for user]"
          wait_for: "User decision before finalizing plan.md"
      escalation:
        trigger: "2 failed verification attempts OR 10 minutes elapsed"
        action: "Present options to user with current findings"

    deep_analysis:
      focus: technical_architecture_design
      approach: comprehensive_planning
      outputs:
      - implementation_strategy
      - technical_approach
      - dependency_analysis
      - integration_patterns
      - risk_mitigation
      - rollback_strategy
    validation: approach_defined

  step_6_5_checkpoint_planning:
    purpose: Save context checkpoint after planning phase complete
    checkpoint: true
    memory_action: save
    activities:
    - Save context checkpoint using system-spec-kit skill
    - Record progress up to planning milestone for session recovery
    - Preserve planning decisions, exploration findings, and technical approach
    tool_invocation:
      command: Read(".opencode/skill/system-spec-kit/SKILL.md")
      note: "Intermediate checkpoint - planning phase complete"
    outputs:
    - checkpoint_file: "[SPEC_FOLDER]/memory/checkpoint__planning_complete.md"
    validation: checkpoint_saved

  step_7_task_breakdown:
    purpose: Break plan into executable implementation tasks (Level 1+ requirement)
    level_requirement: "Level 1+ (Baseline - required at all levels)"
    activities:
    - Run check-prerequisites.sh --json to get FEATURE_DIR
    - Load plan.md for tech stack and architecture
    - Load spec.md for user stories and priorities
    - Load optional artifacts (research)
    - Extract user stories with priorities (P0, P1, P2, P3)
    - Generate tasks organized by user story
    - Create dependency graph for task ordering
    - Mark parallel-executable tasks with [P]
    - Define task phases (Setup, Tests, Core, Integration, Polish)
    - Generate time estimates (15-60 min per task)
    - Create tasks.md with proper structure (required at all levels)
    - Validate task format and coverage
    outputs:
    - tasks.md: implementation_breakdown
    - task_phases: defined
    - dependencies: mapped
    - parallel_markers: assigned
    template: .opencode/skill/system-spec-kit/templates/level_2/tasks.md  # Use level from available_templates based on complexity
    deep_analysis:
      focus: implementation_task_design
      approach: systematic_breakdown
      outputs:
      - task_prioritization
      - dependency_ordering
      - validation_checkpoints
      - incremental_milestones
    validation: tasks_documented

    # â›” PHASE GATE CHECKPOINT
    phase_gate_checkpoint:
      trigger: "After Step 7 completes"
      action: |
        STOP and verify Phase Gate before proceeding:
        1. Verify spec.md exists â†’ If not, return to Step 3
        2. Verify plan.md exists â†’ If not, return to Step 6
        3. Verify tasks.md exists â†’ If not, this step failed
        4. Verify no [NEEDS CLARIFICATION] in spec.md
        5. Mark "PHASE GATE: âœ… PASSED" in tracking table
        6. ONLY THEN proceed to Step 8
      enforcement: HARD_BLOCK

  step_8_analysis:
    purpose: Verify consistency across all artifacts

    # PRE-PHASE: Smart parallel dispatch check
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [ code, docs, analysis ]
      complexity_boost: 10 # Analysis benefits from parallel investigation
      decision_logic: |
        BEFORE starting this phase, evaluate parallel dispatch:
        1. Check for override phrases in user request
        2. Check for session preference (from previous "Auto-decide" selection)
        3. Check for sequential dependencies (skip if detected)
        4. Calculate phase complexity using parallel_dispatch_config
        5. Apply thresholds:
           - <20% â†’ proceed directly (no parallel agents)
           - â‰¥20% + 2 domains â†’ ALWAYS ask user
           NOTE: No auto-dispatch - always ask before parallel dispatch
      on_parallel_dispatch:
        agents:
        - name: "consistency_analyzer"
          focus: "Cross-artifact consistency and requirement coverage"
          model: "{worker_model|opus}"
        - name: "gap_detector"
          focus: "Missing requirements, underspecification, edge cases"
          model: "{worker_model|opus}"
        dispatch_note: "Spawn agents in SINGLE message for parallel execution"
      fallback: "Proceed with activities below if dispatch fails or user chooses direct"

    activities:
    - Load all artifacts (spec.md, plan.md, tasks.md)
    - Build requirements inventory from spec
    - Build task coverage mapping from tasks
    - Run detection passes for:
      - Duplication detection
      - Ambiguity detection
      - Underspecification gaps
      - Constitution alignment
      - Coverage analysis
      - Inconsistency checks
    - Assign severity levels (CRITICAL, HIGH, MEDIUM, LOW)
    - Generate consistency report
    - Generate coverage verification
    - Generate gap analysis
    - Suggest remediations (non-destructive, user must approve)
    outputs:
    - consistency_report
    - coverage_verification
    - alignment_check
    - gap_analysis
    deep_analysis:
      focus: comprehensive_codebase_analysis
      approach: systematic_investigation
      outputs:
      - current_state_assessment
      - gap_identification
      - consistency_verification
      - integration_points
      - existing_patterns
    validation: consistency_verified

  step_9_implementation_check:
    purpose: Verify all prerequisites for implementation
    activities:
    - Run check-prerequisites.sh --json --require-tasks
    - Verify plan.md and tasks.md exist
    - Check all checklists status
    - Count total, completed, incomplete items
    - Verify no blockers exist
    - Verify environment is ready
    - Verify API endpoints accessible (if applicable)
    - Verify authentication working (if applicable)
    - Verify dependencies loaded
    - Generate implementation greenlight report
    checks:
      prerequisites: verified
      blockers: none
      environment: ready
    deep_analysis:
      focus: implementation_readiness
      approach: comprehensive_validation
      outputs:
      - environment_verification
      - dependency_confirmation
      - blocker_resolution
      - implementation_greenlight
    validation: prerequisites_verified

  step_10_development:
    purpose: Execute implementation following task plan

    # PRE-PHASE: Smart parallel dispatch check
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [ code, testing ]
      complexity_boost: 15 # Development is inherently complex
      decision_logic: |
        BEFORE starting this phase, evaluate parallel dispatch:
        1. Check for override phrases in user request
        2. Check for session preference (from previous "Auto-decide" selection)
        3. Check for sequential dependencies (skip if detected)
        4. Calculate phase complexity using parallel_dispatch_config
        5. Apply thresholds:
           - <20% â†’ proceed directly (no parallel agents)
           - â‰¥20% + 2 domains â†’ ALWAYS ask user
           NOTE: No auto-dispatch - always ask before parallel dispatch
      on_parallel_dispatch:
        agents:
        - name: "implementation_agent"
          focus: "Core implementation tasks from tasks.md"
          model: "{worker_model|opus}"
        - name: "test_agent"
          focus: "Test implementation and validation"
          model: "{worker_model|opus}"
        dispatch_note: "Spawn agents in SINGLE message for parallel execution"
        warning: "Development tasks may have dependencies - verify task order before parallel execution"
      fallback: "Proceed with activities below if dispatch fails or user chooses direct"

    activities:
    - Load tasks.md and parse task structure
    - Execute implementation phase by phase
    - Setup first (project structure, dependencies, configuration)
    - Follow TDD approach (tests before code where applicable)
    - Core development (models, services, endpoints)
    - Integration work (database, middleware, logging)
    - Polish and validation (unit tests, optimization, docs)
    - Respect task dependencies (sequential vs parallel)
    - Update task checklist progressively (mark [X] when complete)
    - Validate against acceptance criteria
    - Log progress after each completed task
    - Document any deviations from plan
    approach: autonomous_implementation_with_checkpoints
    requirements:
    - follow: Check skills folder for coding standards
    - update: task_checklist_progressively
    - test: before_commit
    - validate: continuously
    checkpoints:
      major_changes:
        action: log_progress
        validation: self_verify
      issues_found:
        action: document_resolution
        validation: verify_fix
      architecture_change:
        action: note_deviation
        validation: verify_alignment

    # CONFIDENCE CHECKPOINT
    # Applied per-task during implementation
    confidence_checkpoint:
      evaluate_at: "Before each significant code change"
      per_task_assessment:
        scoring_factors:
        - factor: "Implementation clarity"
          weight: 0.35
          assess: "Is the approach for this task clear?"
        - factor: "Pattern alignment"
          weight: 0.30
          assess: "Does this follow existing codebase patterns?"
        - factor: "Risk awareness"
          weight: 0.35
          assess: "Are side effects and edge cases understood?"
        thresholds:
          high_80_plus:
            action: "Implement task, mark [x] when complete"
            log: "Task [T###]: Confidence [NN%] - proceeding"
          medium_40_79:
            action: "Implement with extra validation"
            log: "Task [T###]: Confidence [NN%] - implementing with caution"
            requirement: "Add inline comments explaining approach for review"
          low_below_40:
            action: "STOP - Do not implement uncertain code"
            format: |
              "Implementation confidence low for task [T###] ([NN%]):
              - A) Research: [investigate specific technical question]
              - B) Simplify: [reduce scope to well-understood approach]
              - C) Skip: [defer task with documented reason]"
            wait_for: "Resolution before implementing task"
      citation_requirement: |
        Code changes must be traceable:
        - Reference task ID in commit messages
        - Cite pattern sources in comments for non-obvious approaches
        - Use [DEVIATION: reason] for plan departures

    deep_analysis:
      focus: implementation_execution
      approach: iterative_development_with_validation
      outputs:
      - code_implementation
      - test_validation
      - progressive_verification
      - quality_assurance
      - deviation_documentation
    validation: development_complete

    # â”€â”€ DEBUG INTEGRATION (for autonomous mode) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    debug_integration:
      failure_tracking:
        enabled: true
        counter_name: "task_failure_count"
        reset_on: "new_task"
        threshold: 3

      on_threshold_reached:
        if_auto_debug_flag:
          action: "auto_dispatch_debug"
          log: "ðŸ”§ Auto-dispatching debug agent (3+ failures, :auto-debug enabled)"
        else:
          action: "suggest_debug"
          prompt: |
            âš ï¸ Multiple fix attempts failed (3+) for task {current_task_id}

            Would you like to delegate to a debug agent?

            A) Yes - Dispatch debug agent for fresh analysis
            B) No - Continue debugging manually
            C) Skip task - Move to next task
            D) Pause - Stop workflow and review

      debug_dispatch:
        subagent_type: "general-purpose"  # Claude Code: "general-purpose" | OpenCode: "general"
        timeout_ms: 120000
        context_includes:
        - error_message
        - affected_files
        - previous_attempts
        - current_task_id
        on_complete: "show_checkpoint"

    # â›” COMPLETION CHECKPOINT (CRITICAL)
    completion_checkpoint:
      enforcement: HARD_BLOCK
      before_marking_complete: |
        VERIFY before marking Step 10 as complete:
        1. Read tasks.md file
        2. Count tasks with [ ] (incomplete) vs [x] (complete)
        3. IF any tasks show [ ]:
           - DO NOT mark step complete
           - Continue implementation until ALL tasks show [x]
        4. IF all tasks show [x]:
           - Verify code actually works (no console errors)
           - Mark Step 10: âœ… COMPLETED
      failure_action: "Continue development - do not proceed to Step 11"

  step_10_5_checkpoint_development:
    purpose: Save context checkpoint after development phase complete
    checkpoint: true
    memory_action: save
    activities:
    - Save context checkpoint using system-spec-kit skill
    - Record progress up to development milestone for session recovery
    - Preserve implementation decisions, code changes, and debugging insights
    tool_invocation:
      command: Read(".opencode/skill/system-spec-kit/SKILL.md")
      note: "Intermediate checkpoint - development phase complete"
    outputs:
    - checkpoint_file: "[SPEC_FOLDER]/memory/checkpoint__development_complete.md"
    validation: checkpoint_saved

  step_11_checklist_verify:
    purpose: Verify all P0/P1 checklist items are complete before claiming completion
    blocking: true  # CRITICAL - this step blocks progression for Level 2+
    level_requirement: "Level 2+"
    activities:
    - Load checklist.md from spec folder
    - Verify ALL P0 items are marked [x] with evidence
    - Verify ALL P1 items are either:
      - Marked [x] with evidence, OR
      - Have documented user approval to defer
    - P2 items may be deferred without approval
    - Document verification results with evidence format
    evidence_format: "- [x] Task description [EVIDENCE: file.js:45-67 - implementation verified]"
    evidence_log_pattern: "[E:filename]"
    p0_enforcement:
      blocking: true
      on_incomplete: |
        â›” P0 ITEMS INCOMPLETE - Cannot proceed to Step 12
        
        Incomplete P0 items:
        {incomplete_items}
        
        WORKFLOW HALTED. Complete all P0 items before proceeding.
    p1_enforcement:
      blocking: soft
      allow_deferral: true
      on_incomplete: |
        âš ï¸ P1 items incomplete. Options:
        A) Complete remaining P1 items
        B) Document deferral reasons and proceed
    outputs:
    - checklist_verification_report
    - evidence_documentation
    validation: all_p0_complete

  step_12_completion:
    purpose: Generate implementation summary and verify completion
    activities:
    - Verify all tasks completed
    - Check implemented features match specification
    - Validate tests pass and coverage meets requirements
    - Confirm implementation follows technical plan
    - Generate implementation-summary.md with:
      - files_modified_created
      - verification_steps_taken
      - deviations_from_plan
      - skill_updates
      - recommended_next_steps
      - browser_testing_results
    - Update all task status to completed
    - Mark validation passed
    - Verify staging if environment provided
    summary_document:
      location: "[SPEC_FOLDER]/implementation-summary.md"
      required_sections:
      - files_modified_created
      - verification_steps_taken
      - deviations_from_plan
      - skill_updates
      - recommended_next_steps
      - browser_testing_results
    verification_summary:
      checklist_verification:
        required: true # for Level 2+
        must_include:
        - Total items verified count
        - P0 items status (all must be complete)
        - P1 items status (all complete or deferred with approval)
        - Deferred P2 items with reasons
        - Link to updated checklist.md
    final_checklist:
    - update_task_status: completed
    - validation_passed: confirmed
    - summary_created: true
    - staging_verified: true
    - checklist_verification_complete: true # Level 2+
    deep_analysis:
      focus: completion_documentation
      approach: comprehensive_summary
      outputs:
      - implementation_summary
      - change_documentation
      - validation_results
      - next_steps_recommendation
    validation: implementation_complete

    # â›” COMPLETION CHECKPOINT (CRITICAL)
    completion_checkpoint:
      enforcement: HARD_BLOCK
      before_marking_complete: |
        VERIFY before marking Step 12 as complete:
        1. Check if implementation-summary.md exists in spec folder
        2. IF file does not exist:
           - DO NOT mark step complete
           - CREATE the file with all required sections
        3. IF file exists:
           - Verify all required_sections are present
           - Mark Step 12: âœ… COMPLETED
      required_file: "[SPEC_FOLDER]/implementation-summary.md"
      failure_action: "Create implementation-summary.md before proceeding"

  step_13_save_context:
    purpose: Save conversation context for documentation and team sharing
    activities:
    - Invoke system-spec-kit skill
    - Preserve session metadata and timeline
    - Preserve full dialogue flow with decisions
    - Auto-generate workflow flowcharts
    - Preserve file changes and implementation details
    - Index memory file for immediate search availability
    # â”€â”€ MANDATORY MEMORY CREATION (Memory Save Rule Enforcement) â”€â”€â”€â”€
    memory_creation:
      enforcement: HARD_BLOCK
      method: "MUST use generate-context.js script"
      command: |
        node .opencode/skill/system-spec-kit/scripts/memory/generate-context.js [spec-folder-path]
      forbidden:
        tools: [ Write, Edit ]
        action: "NEVER manually create memory files"
        paths: [ "*/memory/*.md", "specs/*/memory/*" ]
      violation_recovery: |
        IF Write/Edit tool used on memory/ path:
        1. DELETE the manually created file
        2. Execute generate-context.js with spec-folder-path
        3. Verify ANCHOR format in generated file
        4. Index via memory_save MCP tool

    tool_invocation:
      command: 'Read(".opencode/skill/system-spec-kit/SKILL.md")'
      note: 'Use command: Read(".opencode/skill/system-spec-kit/SKILL.md") to activate context saving'
    description: |
      Preserve comprehensive conversation context including:
      - Session metadata and timeline
      - Full dialogue flow with decisions
      - Auto-generated workflow flowcharts
      - File changes and implementation details
    outputs:
    - context_file: "[SPEC_FOLDER]/memory/[DD-MM-YY_HH-MM]__session.md"
    - workflow_flowchart: auto_generated
    - decision_documentation: preserved
    validation: context_saved_successfully
    note: |
      Context saved to memory/ subfolder within spec folder.
      Auto-triggered by skill when conversation reaches threshold or keywords detected.

    # â”€â”€ SEMANTIC MEMORY INTEGRATION (v12.1.0) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    post_save_indexing:
      purpose: "Index memory file immediately for search availability"
      mcp_tool: memory_save
      invocation: |
        spec_kit_memory_memory_save({
          filePath: "[SPEC_FOLDER]/memory/[DD-MM-YY_HH-MM]__session.md"
        })
      critical_note: "Call semantic memory MCP DIRECTLY - NEVER through Code Mode"
      when: "Immediately after memory file is written to disk"

    anchor_requirements:
      enforcement: MANDATORY
      minimum_anchors: 2
      pattern: "[context-type]-[keywords]-[spec-number]"
      format: "<!-- ANCHOR:ID --> content <!-- /ANCHOR:ID -->"
      case: "UPPERCASE recommended for visibility"
      required_sections:
      - context_type: "general"
        section: "Session summary with key outcomes"
        example_id: "GENERAL-SESSION-SUMMARY-{spec#}"
        example: |
          <!-- ANCHOR:GENERAL-SESSION-SUMMARY-{spec#} -->
          ## Session Summary
          Implemented X, resolved Y...
          <!-- /ANCHOR:GENERAL-SESSION-SUMMARY-{spec#} -->
      - context_type: "decision"
        section: "Key decisions made during session"
        example_id: "DECISION-{topic}-{spec#}"
        example: |
          <!-- ANCHOR:DECISION-{topic}-{spec#} -->
          ## Key Decisions
          - Chose approach A because...
          <!-- /ANCHOR:DECISION-{topic}-{spec#} -->
      optional_sections:
      - context_type: "implementation"
        section: "Code patterns or solutions implemented"
        example_id: "IMPLEMENTATION-{feature}-{spec#}"
      - context_type: "files"
        section: "Files modified during session"
        example_id: "FILES-{spec#}"
      benefit: "93% token savings on anchor-based retrieval"
      reference: "See /memory:save Step 3 for full anchor documentation"

    importance_tier:
      assign: important
      rationale: "Complete workflow represents significant implementation work"
      promotion_note: "Use memory_update() to promote to 'critical' if this becomes foundational reference"
      tier_reference: |
        constitutional: Core project rules (auto-surface always)
        critical: Foundational decisions (high priority in search)
        important: Significant work like implementations (this workflow)
        normal: Standard context (default)
        temporary: Short-term notes
        deprecated: Outdated but retained

  step_14_handover_check:
    purpose: Offer session handover before workflow completion
    activities:
    - Check if user needs session continuity documentation
    - Offer to run /spec_kit:handover for comprehensive handover
    - Present options for workflow completion
    options:
    - label: "Run Handover"
      description: "Run /spec_kit:handover for session continuity"
      action: "Execute handover workflow"
    - label: "Skip"
      description: "Complete workflow without handover"
      action: "Proceed to termination"
    note: "Handover is optional but recommended for complex implementations"
    validation: handover_offered

termination:
  after_step: 14
  message: "SpecKit workflow completed successfully. Workflow terminated after step 14 (handover check)."

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CHECKPOINT PROTOCOL FOR OPTIONAL WORKFLOWS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
checkpoint_protocol:
  display_format: |
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ðŸ“ WORKFLOW CHECKPOINT - {checkpoint_title}                    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ {checkpoint_content}                                           â”‚
    â”‚                                                                â”‚
    â”‚ Current workflow progress:                                      â”‚
    â”‚ {progress_display}                                             â”‚
    â”‚                                                                â”‚
    â”‚ {continue_prompt}                                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  autonomous_behavior:
    # In autonomous mode, checkpoints still pause for user confirmation
    # This is intentional - optional workflows are significant decision points
    pause_for_confirmation: true
    default_action_on_timeout: "continue"
    timeout_seconds: 300 # 5 minute timeout before auto-continue

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# QUALITY STANDARDS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
quality_standards:
  documentation:
  - production_ready_examples
  - defensive_programming_patterns
  - error_handling_strategies
  - comprehensive_test_coverage
  code_examples:
  - working_snippets
  - proper_error_handling
  - performance_optimized
  - accessibility_compliant
  - browser_compatible
  analysis_depth:
  - edge_cases_covered
  - failure_modes_documented
  - recovery_strategies_defined
  - monitoring_approaches_specified

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AUTONOMOUS EXECUTION GUIDANCE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
autonomous_execution:
  principle: "Execute workflow steps sequentially without user approval gates"

  decision_making:
  - Analyze requirements thoroughly
  - Make informed technical decisions
  - Document reasoning and alternatives
  - Proceed with best judgment
  - Log all significant decisions

  validation_approach:
  - Self-validate at each checkpoint
  - Verify against quality standards
  - Test implementation continuously
  - Document validation results
  - Ensure consistency with spec

  uncertainty_handling:
  - Research thoroughly before deciding
  - Document assumptions clearly
  - Choose conservative approach
  - Note areas needing review
  - Flag high-risk decisions

  progress_tracking:
  - Update task checklists progressively
  - Log milestone completion
  - Document deviations from plan
  - Track validation results
  - Maintain clear audit trail

  completion_criteria:
  - All workflow steps completed
  - Implementation validated
  - Documentation generated
  - Quality standards met
  - Context saved

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ERROR RECOVERY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
error_recovery:
  step_validation_fails:
    action: "Review requirements, ask clarifying questions, retry step"
  tests_fail:
    action: "Debug, fix, re-run before marking complete"
  prerequisites_insufficient:
    action: "Return to prior workflow phase or ask user for guidance"
  environment_unavailable:
    action: "Skip browser testing, document limitation"
  unexpected_error:
    action: "Log error, document state, attempt graceful recovery"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RULES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
rules:
  ALWAYS:
  - follow_workflow_sequence
  - document_all_changes
  - validate_before_completion
  - use_browser_for_staging_analysis
  - self_validate_and_proceed
  - do_not_prompt_for_user_approval
  - limit_context_to_active_scope
  - generate_comprehensive_documentation
  - verify_continuously
  - log_decisions_and_deviations
  - use_checklist_for_verification_level_2_plus
  - mark_checklist_items_with_evidence
  - complete_all_p0_items_before_done
  - get_user_approval_for_p1_deferrals

  NEVER:
  - skip_workflow_steps
  - ignore_blockers
  - submit_without_validation
  - skip_browser_testing_without_documenting_limitation
  - over_engineer_or_expand_scope
  - break_existing_functionality
  - proceed_without_self_validation
  - invent_new_patterns_when_existing_work
  - claim_completion_without_checklist_verification_level_2_plus
  - skip_p0_checklist_items
  - defer_p1_items_without_user_approval

  VALIDATION_REQUIRED:
  - Before moving to next step
  - After each code change
  - Before committing changes
  - After browser testing
  - At completion summary

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SUCCESS CRITERIA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
success:
  specification:
  - Requirements clearly defined
  - Acceptance criteria documented
  - Technical approach planned
  - Dependencies identified

  implementation:
  - Code follows standards
  - Tests pass
  - Browser validation complete
  - Performance acceptable

  documentation:
  - Spec folder complete
  - Implementation summary created
  - Deviations documented
  - Context saved

  quality:
  - Checklist validated
  - No regressions introduced
  - Functionality preserved
  - Standards maintained
