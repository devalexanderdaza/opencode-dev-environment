# Embeddings Factory - Arquitectura Multi-Provider

Sistema de embeddings flexible que soporta mÃºltiples backends con fallback robusto y DB por perfil.

## ğŸ“ Estructura

```
embeddings/
â”œâ”€â”€ profile.js              # Define EmbeddingProfile y gestiÃ³n de slugs
â”œâ”€â”€ factory.js              # Factory que selecciona el provider adecuado
â””â”€â”€ providers/
    â”œâ”€â”€ hf-local.js         # HuggingFace local (default)
    â”œâ”€â”€ openai.js           # OpenAI embeddings API
    â””â”€â”€ ollama.js           # Ollama (futuro)
```

## ğŸ¯ Providers Disponibles

| Provider | DimensiÃ³n | Requisitos | CuÃ¡ndo usar |
|----------|-----------|------------|-------------|
| **hf-local** | 768 | Solo Node.js | Default, privacidad, offline |
| **openai** | 1536/3072 | `OPENAI_API_KEY` | Cloud, auto-detect si existe key |
| **ollama** | 768 | Ollama service | (No implementado aÃºn) |

## ğŸ”§ ConfiguraciÃ³n

### Auto-detecciÃ³n (Recomendado)

```bash
# Sin configuraciÃ³n: usa HF local
node context-server.js

# Con OpenAI: auto-detecta la key
export OPENAI_API_KEY=sk-...
node context-server.js
```

### Override Manual

```bash
# Forzar HF local aunque exista OPENAI_API_KEY
export EMBEDDINGS_PROVIDER=hf-local

# Forzar OpenAI (requiere key)
export EMBEDDINGS_PROVIDER=openai
export OPENAI_API_KEY=sk-...

# Configurar modelo especÃ­fico
export OPENAI_EMBEDDINGS_MODEL=text-embedding-3-large  # 3072 dims
export HF_EMBEDDINGS_MODEL=nomic-ai/nomic-embed-text-v1.5
```

## ğŸ’¾ DB por Perfil

Cada combinaciÃ³n Ãºnica de `{provider, model, dimension}` usa su propia base de datos SQLite:

```
database/
â”œâ”€â”€ context-index.sqlite                              # Legacy (hf-local + nomic + 768)
â”œâ”€â”€ context-index__openai__text-embedding-3-small__1536.sqlite
â”œâ”€â”€ context-index__openai__text-embedding-3-large__3072.sqlite
â””â”€â”€ context-index__hf-local__custom-model__768.sqlite
```

**Ventajas:**
- âœ… No hay "dimension mismatch" errors
- âœ… Cambiar de provider no requiere migraciÃ³n
- âœ… Puedes experimentar sin perder datos

## ğŸ“– API Usage

### Generar Embeddings

```javascript
const embeddings = require('./embeddings');

// Para indexar documentos
const docEmbedding = await embeddings.generateDocumentEmbedding('texto...');

// Para bÃºsqueda
const queryEmbedding = await embeddings.generateQueryEmbedding('bÃºsqueda...');
```

### Obtener Metadata

```javascript
// Info del provider actual
const metadata = embeddings.getProviderMetadata();
console.log(metadata);
// {
//   provider: 'openai',
//   model: 'text-embedding-3-small',
//   dim: 1536,
//   healthy: true
// }

// Perfil completo
const profile = embeddings.getEmbeddingProfile();
console.log(profile.getDatabasePath('/base/dir'));
// '/base/dir/context-index__openai__text-embedding-3-small__1536.sqlite'
```

### Pre-warmup (Recomendado en startup)

```javascript
await embeddings.preWarmModel();
// Descarga/carga el modelo en background
```

## ğŸ”„ Precedencia de ConfiguraciÃ³n

1. `EMBEDDINGS_PROVIDER` explÃ­cito (si no es `auto`)
2. Auto-detecciÃ³n: OpenAI si existe `OPENAI_API_KEY`
3. Fallback: HF local

## ğŸ›¡ï¸ Fallback Robusto

Si OpenAI falla durante warmup/healthcheck (auth, red, rate limit), el sistema degrada automÃ¡ticamente a HF local **antes** de indexar datos, previniendo mezcla de dimensiones.

## ğŸ§ª Testing

```bash
# Test bÃ¡sico (sin cargar modelos pesados)
node scripts/test-embeddings-factory.js

# Con OpenAI
OPENAI_API_KEY=sk-... node scripts/test-embeddings-factory.js
```

## ğŸ“ Compatibilidad Legacy

La API pÃºblica se mantiene 100% compatible. CÃ³digo existente funciona sin cambios:

```javascript
// âœ… Sigue funcionando
const { generateDocumentEmbedding, getEmbeddingDimension } = require('./embeddings');
```

## ğŸ”® Futuro: Ollama Provider

Para implementar el provider de Ollama:

1. Crear `providers/ollama.js` similar a `openai.js`
2. HTTP requests a `http://localhost:11434/api/embeddings`
3. AÃ±adir `case 'ollama':` en `factory.js`

## ğŸ“Š ComparaciÃ³n de Providers

| CaracterÃ­stica | HF Local | OpenAI | Ollama |
|----------------|----------|--------|--------|
| Coste | Gratis | ~$0.02/1M tokens | Gratis |
| Latencia | Media | Baja-Media | Baja |
| Privacidad | âœ… Local | âŒ Cloud | âœ… Local |
| Offline | âœ… SÃ­ | âŒ No | âœ… SÃ­ |
| Setup | FÃ¡cil | API key | Install + model |
| DimensiÃ³n | 768 fija | Configurable | Depende modelo |

## ğŸ› Troubleshooting

### "Dimension mismatch"
Ya no deberÃ­a ocurrir. Cada perfil tiene su DB. Si ves este error, verifica que no estÃ©s usando `MEMORY_DB_PATH` forzado.

### "OpenAI provider requiere OPENAI_API_KEY"
Fuerza HF local: `export EMBEDDINGS_PROVIDER=hf-local`

### "Model not loaded"
HF local descarga ~274MB en primera ejecuciÃ³n. Paciencia en cold start.

### Ver provider activo
```bash
# En el MCP tool memory_health
{
  "embeddingProvider": {
    "provider": "...",
    "model": "...",
    "dimension": ...
  }
}
```
