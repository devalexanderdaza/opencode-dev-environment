/**
 * Vector Index Module - sqlite-vec based vector storage
 *
 * Provides persistent vector storage for memory embeddings using
 * sqlite-vec extension. Supports cross-spec-folder search with
 * synchronized rowid linkage between metadata and vectors.
 *
 * UPGRADE NOTE (2025-12-09):
 * - Changed from 384-dim to 768-dim vectors (nomic-embed-text-v1.5)
 * - Requires database migration: run migrate-to-nomic.js
 * - Uses task-specific prefixes via embeddings.js
 *
 * Phase 1 & 3 enhancements:
 * - T1.3: linkRelatedOnSave - auto-links related memories on save
 * - T3.2: recordAccess - tracks memory usage for analytics
 * - T3.4: cachedSearch - LRU-cached search for performance
 * - getRelatedMemories - retrieves pre-computed related memories
 *
 * @module vector-index
 * @version 11.0.0
 */

'use strict';

const Database = require('better-sqlite3');
const sqliteVec = require('sqlite-vec');
const path = require('path');
const os = require('os');
const fs = require('fs');

// Lazy-load embeddings module to avoid circular dependencies
let embeddingsModule = null;
function getEmbeddingsModule() {
  if (!embeddingsModule) {
    embeddingsModule = require('./embeddings');
  }
  return embeddingsModule;
}

// ───────────────────────────────────────────────────────────────
// CONFIGURATION
// ───────────────────────────────────────────────────────────────

const EMBEDDING_DIM = 768; // nomic-embed-text-v1.5
// Project-local database for memory storage
// V12.1: Updated path after consolidation to skill/system-memory/
const DEFAULT_DB_PATH = process.env.MEMORY_DB_PATH || 
  path.join(process.cwd(), '.opencode', 'skill', 'system-memory', 'database', 'memory-index.sqlite');
const DB_PERMISSIONS = 0o600; // Owner read/write only

// ───────────────────────────────────────────────────────────────
// DATABASE SINGLETON
// ───────────────────────────────────────────────────────────────

let db = null;
let dbPath = DEFAULT_DB_PATH;
let sqliteVecAvailable = true; // Track if sqlite-vec is available (NFR-R01)

/**
 * Initialize or get database connection
 * Creates schema on first use
 *
 * @param {string} [customPath] - Override default database path (for testing)
 * @returns {Object} better-sqlite3 database instance
 */
function initializeDb(customPath = null) {
  if (db && !customPath) {
    return db;
  }

  const targetPath = customPath || dbPath;

  // Ensure directory exists
  const dir = path.dirname(targetPath);
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true, mode: 0o700 });
  }

  // Open database
  db = new Database(targetPath);

  // Load sqlite-vec extension with graceful degradation (NFR-R01, CHK123)
  try {
    sqliteVec.load(db);
    sqliteVecAvailable = true;
  } catch (vecError) {
    sqliteVecAvailable = false;
    console.warn(`[vector-index] sqlite-vec extension not available: ${vecError.message}`);
    console.warn('[vector-index] Falling back to anchor-only mode (no vector search)');
    console.warn('[vector-index] Install sqlite-vec: brew install sqlite-vec (macOS)');
  }

  // Enable WAL mode for concurrent access (FR-010b)
  db.pragma('journal_mode = WAL');

  // Performance optimizations (Phase 3 - NFR performance targets T3.8)
  db.pragma('synchronous = NORMAL');
  db.pragma('cache_size = -64000');      // 64MB cache
  db.pragma('temp_store = MEMORY');
  db.pragma('mmap_size = 268435456');    // 256MB memory-mapped I/O

  // Create schema if needed
  createSchema(db);

  // Upgrade schema with new columns (safe for existing DBs)
  upgradeSchema(db);

  // Set file permissions (T021)
  if (!customPath) {
    try {
      fs.chmodSync(targetPath, DB_PERMISSIONS);
    } catch (err) {
      console.warn(`[vector-index] Could not set permissions on ${targetPath}: ${err.message}`);
    }
  }

  dbPath = targetPath;
  return db;
}

/**
 * Create database schema
 * @param {Object} database - better-sqlite3 instance
 */
function createSchema(database) {
  // Check if tables exist
  const tableExists = database.prepare(`
    SELECT name FROM sqlite_master
    WHERE type='table' AND name='memory_index'
  `).get();

  if (tableExists) {
    return; // Schema already exists
  }

  // Create memory_index table (metadata only)
  database.exec(`
    CREATE TABLE memory_index (
      id INTEGER PRIMARY KEY,
      spec_folder TEXT NOT NULL,
      file_path TEXT NOT NULL,
      anchor_id TEXT,
      title TEXT,
      trigger_phrases TEXT,
      importance_weight REAL DEFAULT 0.5,
      created_at TEXT NOT NULL,
      updated_at TEXT NOT NULL,
      embedding_model TEXT,
      embedding_generated_at TEXT,
      embedding_status TEXT DEFAULT 'pending' CHECK(embedding_status IN ('pending', 'success', 'failed', 'retry')),
      retry_count INTEGER DEFAULT 0,
      last_retry_at TEXT,
      failure_reason TEXT,
      UNIQUE(spec_folder, file_path, anchor_id)
    )
  `);

  // Create vec_memories virtual table (only if sqlite-vec is available)
  if (sqliteVecAvailable) {
    database.exec(`
      CREATE VIRTUAL TABLE vec_memories USING vec0(
        embedding FLOAT[${EMBEDDING_DIM}]
      )
    `);
  }

  // Create indexes
  database.exec(`
    CREATE INDEX idx_spec_folder ON memory_index(spec_folder);
    CREATE INDEX idx_created_at ON memory_index(created_at);
    CREATE INDEX idx_importance ON memory_index(importance_weight DESC);
    CREATE INDEX idx_embedding_status ON memory_index(embedding_status);
    CREATE INDEX idx_retry_eligible ON memory_index(embedding_status, retry_count, last_retry_at)
  `);

  console.warn('[vector-index] Schema created successfully');
}

/**
 * Upgrade schema with new columns (backward compatible)
 *
 * Adds new columns to existing databases without breaking existing data.
 * Uses try-catch pattern to safely ignore "column already exists" errors.
 *
 * Phase 1: Related memories linking (T1.4)
 * Phase 3: Confidence and usage tracking (T3.1, T3.8)
 *
 * @param {Object} database - better-sqlite3 instance
 */
function upgradeSchema(database) {
  const schemaUpdates = [
    // Phase 1: Related memories linking (T1.4)
    'ALTER TABLE memory_index ADD COLUMN related_memories TEXT',

    // Phase 3: Confidence and usage tracking (T3.1)
    'ALTER TABLE memory_index ADD COLUMN confidence REAL DEFAULT 0.5',
    'ALTER TABLE memory_index ADD COLUMN access_count INTEGER DEFAULT 0',
    'ALTER TABLE memory_index ADD COLUMN last_accessed_at TEXT'
  ];

  for (const sql of schemaUpdates) {
    try {
      database.exec(sql);
    } catch (e) {
      // Column already exists - safe to ignore
      // This is expected behavior for upgrade migrations
    }
  }

  // Add index for cleanup queries (access-based) (T3.8)
  try {
    database.exec('CREATE INDEX idx_last_accessed ON memory_index(last_accessed_at)');
  } catch (e) {
    // Index already exists - safe to ignore
  }

  // Add index for confidence-based queries
  try {
    database.exec('CREATE INDEX idx_confidence ON memory_index(confidence DESC)');
  } catch (e) {
    // Index already exists - safe to ignore
  }
}

// ───────────────────────────────────────────────────────────────
// CORE OPERATIONS
// ───────────────────────────────────────────────────────────────

/**
 * Index a memory with its embedding (synchronized INSERT)
 *
 * @param {Object} params - Memory parameters
 * @param {string} params.specFolder - Spec folder name
 * @param {string} params.filePath - Full path to memory file
 * @param {string} [params.anchorId] - Optional anchor ID
 * @param {string} [params.title] - Memory title
 * @param {string[]} [params.triggerPhrases] - Trigger phrases array
 * @param {number} [params.importanceWeight=0.5] - Importance score 0-1
 * @param {Float32Array} params.embedding - 768-dim embedding vector
 * @returns {number} Inserted row ID
 */
function indexMemory(params) {
  const database = initializeDb();

  const {
    specFolder,
    filePath,
    anchorId = null,
    title = null,
    triggerPhrases = [],
    importanceWeight = 0.5,
    embedding
  } = params;

  if (!embedding || embedding.length !== EMBEDDING_DIM) {
    throw new Error(`Embedding must be ${EMBEDDING_DIM} dimensions`);
  }

  const now = new Date().toISOString();
  const triggersJson = JSON.stringify(triggerPhrases);
  const embeddingBuffer = Buffer.from(embedding.buffer);

  // Check for existing entry
  const existing = database.prepare(`
    SELECT id FROM memory_index
    WHERE spec_folder = ? AND file_path = ? AND (anchor_id = ? OR (anchor_id IS NULL AND ? IS NULL))
  `).get(specFolder, filePath, anchorId, anchorId);

  if (existing) {
    // Update existing entry
    return updateMemory({
      id: existing.id,
      title,
      triggerPhrases,
      importanceWeight,
      embedding
    });
  }

  // Synchronized INSERT in transaction
  const insertMemory = database.transaction(() => {
    // Determine status based on sqlite-vec availability
    const embeddingStatus = sqliteVecAvailable ? 'success' : 'pending';

    // Step 1: Insert metadata
    const result = database.prepare(`
      INSERT INTO memory_index (
        spec_folder, file_path, anchor_id, title, trigger_phrases,
        importance_weight, created_at, updated_at, embedding_model,
        embedding_generated_at, embedding_status
      ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `).run(
      specFolder, filePath, anchorId, title, triggersJson,
      importanceWeight, now, now, 'nomic-ai/nomic-embed-text-v1.5', now, embeddingStatus
    );

    // sqlite-vec requires BigInt for explicit rowid insertion
    const rowId = BigInt(result.lastInsertRowid);

    // Step 2: Insert embedding with synchronized rowid (only if sqlite-vec available)
    if (sqliteVecAvailable) {
      database.prepare(`
        INSERT INTO vec_memories (rowid, embedding) VALUES (?, ?)
      `).run(rowId, embeddingBuffer);
    }

    return Number(rowId);
  });

  return insertMemory();
}

/**
 * Update an existing memory entry
 *
 * @param {Object} params - Update parameters
 * @param {number} params.id - Row ID to update
 * @param {string} [params.title] - New title
 * @param {string[]} [params.triggerPhrases] - New trigger phrases
 * @param {number} [params.importanceWeight] - New importance
 * @param {Float32Array} [params.embedding] - New embedding
 * @returns {number} Updated row ID
 */
function updateMemory(params) {
  const database = initializeDb();

  const { id, title, triggerPhrases, importanceWeight, embedding } = params;

  const now = new Date().toISOString();

  const updateMemoryTx = database.transaction(() => {
    // Build dynamic update
    const updates = ['updated_at = ?'];
    const values = [now];

    if (title !== undefined) {
      updates.push('title = ?');
      values.push(title);
    }
    if (triggerPhrases !== undefined) {
      updates.push('trigger_phrases = ?');
      values.push(JSON.stringify(triggerPhrases));
    }
    if (importanceWeight !== undefined) {
      updates.push('importance_weight = ?');
      values.push(importanceWeight);
    }
    if (embedding) {
      updates.push('embedding_model = ?');
      updates.push('embedding_generated_at = ?');
      updates.push('embedding_status = ?');
      values.push('nomic-ai/nomic-embed-text-v1.5', now, 'success');
    }

    values.push(id);

    database.prepare(`
      UPDATE memory_index SET ${updates.join(', ')} WHERE id = ?
    `).run(...values);

    // Update embedding if provided
    if (embedding) {
      const embeddingBuffer = Buffer.from(embedding.buffer);

      // Delete old vector (BigInt for vec_memories rowid)
      database.prepare('DELETE FROM vec_memories WHERE rowid = ?').run(BigInt(id));

      // Insert new vector (BigInt required for explicit rowid)
      database.prepare(`
        INSERT INTO vec_memories (rowid, embedding) VALUES (?, ?)
      `).run(BigInt(id), embeddingBuffer);
    }

    return id;
  });

  return updateMemoryTx();
}

/**
 * Delete a memory entry (synchronized DELETE)
 *
 * @param {number} id - Row ID to delete
 * @returns {boolean} True if deleted
 */
function deleteMemory(id) {
  const database = initializeDb();

  const deleteMemoryTx = database.transaction(() => {
    // Delete from vec_memories first (BigInt for rowid)
    database.prepare('DELETE FROM vec_memories WHERE rowid = ?').run(BigInt(id));

    // Delete from memory_index
    const result = database.prepare('DELETE FROM memory_index WHERE id = ?').run(id);

    return result.changes > 0;
  });

  return deleteMemoryTx();
}

/**
 * Delete memory by spec folder and file path
 *
 * @param {string} specFolder - Spec folder name
 * @param {string} filePath - File path
 * @param {string} [anchorId] - Optional anchor ID
 * @returns {boolean} True if deleted
 */
function deleteMemoryByPath(specFolder, filePath, anchorId = null) {
  const database = initializeDb();

  const row = database.prepare(`
    SELECT id FROM memory_index
    WHERE spec_folder = ? AND file_path = ? AND (anchor_id = ? OR (anchor_id IS NULL AND ? IS NULL))
  `).get(specFolder, filePath, anchorId, anchorId);

  if (row) {
    return deleteMemory(row.id);
  }
  return false;
}

/**
 * Get memory by ID
 *
 * @param {number} id - Row ID
 * @returns {Object|null} Memory metadata or null
 */
function getMemory(id) {
  const database = initializeDb();

  const row = database.prepare('SELECT * FROM memory_index WHERE id = ?').get(id);

  if (row && row.trigger_phrases) {
    row.trigger_phrases = JSON.parse(row.trigger_phrases);
  }

  return row || null;
}

/**
 * Get all memories for a spec folder
 *
 * @param {string} specFolder - Spec folder name
 * @returns {Object[]} Array of memory metadata
 */
function getMemoriesByFolder(specFolder) {
  const database = initializeDb();

  const rows = database.prepare(`
    SELECT * FROM memory_index WHERE spec_folder = ? ORDER BY created_at DESC
  `).all(specFolder);

  return rows.map(row => {
    if (row.trigger_phrases) {
      row.trigger_phrases = JSON.parse(row.trigger_phrases);
    }
    return row;
  });
}

/**
 * Get total memory count
 *
 * @returns {number} Total number of indexed memories
 */
function getMemoryCount() {
  const database = initializeDb();
  const result = database.prepare('SELECT COUNT(*) as count FROM memory_index').get();
  return result.count;
}

/**
 * Get count by embedding status
 *
 * @returns {Object} Counts by status
 */
function getStatusCounts() {
  const database = initializeDb();

  const rows = database.prepare(`
    SELECT embedding_status, COUNT(*) as count
    FROM memory_index
    GROUP BY embedding_status
  `).all();

  const counts = { pending: 0, success: 0, failed: 0, retry: 0 };
  for (const row of rows) {
    counts[row.embedding_status] = row.count;
  }

  return counts;
}

/**
 * Get overall statistics for the memory index
 * @returns {Object} Stats including total, success, pending, etc.
 */
function getStats() {
  const counts = getStatusCounts();
  const total = counts.pending + counts.success + counts.failed + counts.retry;

  return {
    total,
    ...counts
  };
}

// ───────────────────────────────────────────────────────────────
// VECTOR SEARCH
// ───────────────────────────────────────────────────────────────

/**
 * Search memories by vector similarity
 *
 * @param {Float32Array|Buffer} queryEmbedding - Query vector (768-dim)
 * @param {Object} [options] - Search options
 * @param {number} [options.limit=10] - Maximum results
 * @param {string} [options.specFolder] - Filter by spec folder
 * @param {number} [options.minSimilarity=0] - Minimum similarity (0-100)
 * @returns {Object[]} Ranked results with similarity scores
 */
function vectorSearch(queryEmbedding, options = {}) {
  // Check if sqlite-vec is available (NFR-R01 graceful degradation)
  if (!sqliteVecAvailable) {
    console.warn('[vector-index] Vector search unavailable - sqlite-vec not loaded');
    return [];
  }

  const database = initializeDb();

  const { limit = 10, specFolder = null, minSimilarity = 0 } = options;

  // Convert to Buffer if Float32Array
  const queryBuffer = queryEmbedding instanceof Buffer
    ? queryEmbedding
    : Buffer.from(queryEmbedding.buffer);

  // Convert minSimilarity (0-100) to max distance (0-2 for cosine)
  // similarity = (1 - distance/2) * 100, so distance = 2 * (1 - similarity/100)
  const maxDistance = 2 * (1 - minSimilarity / 100);

  let sql;
  let params;

  if (specFolder) {
    sql = `
      SELECT
        m.*,
        vec_distance_cosine(v.embedding, ?) as distance,
        ROUND((1 - vec_distance_cosine(v.embedding, ?) / 2) * 100, 2) as similarity
      FROM memory_index m
      JOIN vec_memories v ON m.id = v.rowid
      WHERE m.embedding_status = 'success'
        AND m.spec_folder = ?
        AND vec_distance_cosine(v.embedding, ?) <= ?
      ORDER BY distance ASC
      LIMIT ?
    `;
    params = [queryBuffer, queryBuffer, specFolder, queryBuffer, maxDistance, limit];
  } else {
    sql = `
      SELECT
        m.*,
        vec_distance_cosine(v.embedding, ?) as distance,
        ROUND((1 - vec_distance_cosine(v.embedding, ?) / 2) * 100, 2) as similarity
      FROM memory_index m
      JOIN vec_memories v ON m.id = v.rowid
      WHERE m.embedding_status = 'success'
        AND vec_distance_cosine(v.embedding, ?) <= ?
      ORDER BY distance ASC
      LIMIT ?
    `;
    params = [queryBuffer, queryBuffer, queryBuffer, maxDistance, limit];
  }

  const rows = database.prepare(sql).all(...params);

  return rows.map(row => {
    if (row.trigger_phrases) {
      row.trigger_phrases = JSON.parse(row.trigger_phrases);
    }
    return row;
  });
}

/**
 * Multi-concept AND search - finds memories matching ALL concepts
 *
 * @param {Array<Float32Array|Buffer>} conceptEmbeddings - Array of concept vectors (2-5)
 * @param {Object} [options] - Search options
 * @param {number} [options.limit=10] - Maximum results
 * @param {string} [options.specFolder] - Filter by spec folder
 * @param {number} [options.minSimilarity=50] - Minimum similarity per concept (0-100)
 * @returns {Object[]} Results matching ALL concepts with per-concept scores
 */
function multiConceptSearch(conceptEmbeddings, options = {}) {
  // Check if sqlite-vec is available (NFR-R01 graceful degradation)
  if (!sqliteVecAvailable) {
    console.warn('[vector-index] Multi-concept search unavailable - sqlite-vec not loaded');
    return [];
  }

  const database = initializeDb();

  const concepts = conceptEmbeddings;
  if (!Array.isArray(concepts) || concepts.length < 2 || concepts.length > 5) {
    throw new Error('Multi-concept search requires 2-5 concepts');
  }

  const { limit = 10, specFolder = null, minSimilarity = 50 } = options;

  // Convert to Buffers
  const conceptBuffers = concepts.map(c =>
    c instanceof Buffer ? c : Buffer.from(c.buffer)
  );

  // Convert minSimilarity to max distance
  const maxDistance = 2 * (1 - minSimilarity / 100);

  // Build subquery with distances, then calculate similarities and averages in outer query
  const distanceExpressions = conceptBuffers.map((_, i) =>
    `vec_distance_cosine(v.embedding, ?) as dist_${i}`
  ).join(', ');

  const distanceFilters = conceptBuffers.map((_, i) =>
    `vec_distance_cosine(v.embedding, ?) <= ?`
  ).join(' AND ');

  const folderFilter = specFolder ? 'AND m.spec_folder = ?' : '';

  // Outer query expressions using the computed distances
  const similaritySelect = conceptBuffers.map((_, i) =>
    `ROUND((1 - sub.dist_${i} / 2) * 100, 2) as similarity_${i}`
  ).join(', ');

  const avgDistanceExpr = conceptBuffers.map((_, i) => `sub.dist_${i}`).join(' + ');

  // Build SQL with subquery pattern
  const sql = `
    SELECT
      sub.*,
      ${similaritySelect},
      (${avgDistanceExpr}) / ${concepts.length} as avg_distance
    FROM (
      SELECT
        m.*,
        ${distanceExpressions}
      FROM memory_index m
      JOIN vec_memories v ON m.id = v.rowid
      WHERE m.embedding_status = 'success'
        ${folderFilter}
        AND ${distanceFilters}
    ) sub
    ORDER BY avg_distance ASC
    LIMIT ?
  `;

  // Build params: distances in subquery, folder?, filters, limit
  const params = [
    ...conceptBuffers,                              // for distance expressions
    ...(specFolder ? [specFolder] : []),            // folder filter
    ...conceptBuffers.flatMap(b => [b, maxDistance]), // for distance filter conditions
    limit
  ];

  const rows = database.prepare(sql).all(...params);

  return rows.map(row => {
    if (row.trigger_phrases) {
      row.trigger_phrases = JSON.parse(row.trigger_phrases);
    }
    // Add concept_similarities array and calculate average
    row.concept_similarities = conceptBuffers.map((_, i) => row[`similarity_${i}`]);
    row.avg_similarity = row.concept_similarities.reduce((a, b) => a + b, 0) / concepts.length;
    return row;
  });
}

// ───────────────────────────────────────────────────────────────
// CONTENT EXTRACTION HELPERS
// ───────────────────────────────────────────────────────────────

/**
 * Extract title from memory file content
 *
 * Tries in order:
 * 1. First markdown h1 heading (# Title)
 * 2. First markdown h2 heading (## Title)
 * 3. YAML frontmatter title field
 * 4. First non-empty line
 * 5. Filename without extension (fallback)
 *
 * @param {string} content - Full markdown content
 * @param {string} filename - Fallback filename
 * @returns {string} Extracted title
 */
function extractTitle(content, filename) {
  if (!content || typeof content !== 'string') {
    return filename ? path.basename(filename, path.extname(filename)) : 'Untitled';
  }

  // Try H1 heading: # Title
  const h1Match = content.match(/^#\s+(.+)$/m);
  if (h1Match && h1Match[1]) {
    return h1Match[1].trim();
  }

  // Try H2 heading: ## Title
  const h2Match = content.match(/^##\s+(.+)$/m);
  if (h2Match && h2Match[1]) {
    return h2Match[1].trim();
  }

  // Try YAML frontmatter title
  const yamlMatch = content.match(/^---[\s\S]*?^title:\s*(.+)$/m);
  if (yamlMatch && yamlMatch[1]) {
    return yamlMatch[1].trim().replace(/^["']|["']$/g, '');
  }

  // Try first non-empty line
  const lines = content.split('\n').filter(l => l.trim().length > 0);
  if (lines.length > 0) {
    const firstLine = lines[0].trim();
    // Clean up markdown formatting
    return firstLine.replace(/^#+\s*/, '').substring(0, 100);
  }

  // Fallback to filename
  return filename ? path.basename(filename, path.extname(filename)) : 'Untitled';
}

/**
 * Extract snippet from memory content
 *
 * Returns the first meaningful paragraph or sentence, excluding:
 * - YAML frontmatter
 * - Headings
 * - Empty lines
 *
 * @param {string} content - Full markdown content
 * @param {number} [maxLength=200] - Maximum snippet length
 * @returns {string} First paragraph/sentence as snippet
 */
function extractSnippet(content, maxLength = 200) {
  if (!content || typeof content !== 'string') {
    return '';
  }

  // Remove YAML frontmatter
  let text = content.replace(/^---[\s\S]*?---\n*/m, '');

  // Split into lines
  const lines = text.split('\n');
  const snippetLines = [];

  for (const line of lines) {
    const trimmed = line.trim();

    // Skip empty lines and headings
    if (!trimmed || /^#+\s/.test(trimmed)) {
      // If we already have content, stop at first break
      if (snippetLines.length > 0) {
        break;
      }
      continue;
    }

    // Skip metadata-like lines (key: value at start)
    if (/^[a-z_-]+:\s/i.test(trimmed) && snippetLines.length === 0) {
      continue;
    }

    snippetLines.push(trimmed);

    // Check if we have enough content
    const currentLength = snippetLines.join(' ').length;
    if (currentLength >= maxLength) {
      break;
    }
  }

  let snippet = snippetLines.join(' ');

  // Truncate if too long, break at word boundary
  if (snippet.length > maxLength) {
    snippet = snippet.substring(0, maxLength);
    const lastSpace = snippet.lastIndexOf(' ');
    if (lastSpace > maxLength * 0.7) {
      snippet = snippet.substring(0, lastSpace);
    }
    snippet += '...';
  }

  return snippet;
}

/**
 * Extract tags from memory content
 *
 * Looks for:
 * 1. YAML frontmatter tags field
 * 2. Inline hashtags (#tag)
 *
 * @param {string} content - Full markdown content
 * @returns {string[]} Array of unique tags
 */
function extractTags(content) {
  if (!content || typeof content !== 'string') {
    return [];
  }

  const tags = new Set();

  // Try YAML frontmatter tags
  const yamlTagsMatch = content.match(/^---[\s\S]*?^tags:\s*\[([^\]]+)\]/m);
  if (yamlTagsMatch && yamlTagsMatch[1]) {
    yamlTagsMatch[1].split(',').forEach(tag => {
      const cleaned = tag.trim().replace(/^["']|["']$/g, '');
      if (cleaned) tags.add(cleaned.toLowerCase());
    });
  }

  // Also try YAML list format
  const yamlListMatch = content.match(/^---[\s\S]*?^tags:\s*\n((?:\s*-\s*.+\n?)+)/m);
  if (yamlListMatch && yamlListMatch[1]) {
    yamlListMatch[1].match(/-\s*(.+)/g)?.forEach(match => {
      const tag = match.replace(/^-\s*/, '').trim().replace(/^["']|["']$/g, '');
      if (tag) tags.add(tag.toLowerCase());
    });
  }

  // Find inline hashtags (excluding headings)
  const hashtagMatches = content.match(/(?:^|\s)#([a-zA-Z][a-zA-Z0-9_-]*)/g);
  if (hashtagMatches) {
    hashtagMatches.forEach(match => {
      const tag = match.trim().replace(/^#/, '');
      if (tag && !tag.match(/^[0-9]+$/)) { // Skip pure numbers
        tags.add(tag.toLowerCase());
      }
    });
  }

  return Array.from(tags);
}

/**
 * Extract date from memory file
 *
 * Tries in order:
 * 1. YAML frontmatter date field
 * 2. Date pattern in filename (YYYY-MM-DD or DD-MM-YY)
 * 3. null if not found
 *
 * @param {string} content - Full markdown content
 * @param {string} filePath - File path for filename parsing
 * @returns {string|null} ISO date string or null
 */
function extractDate(content, filePath) {
  if (content && typeof content === 'string') {
    // Try YAML frontmatter date
    const dateMatch = content.match(/^---[\s\S]*?^date:\s*(.+)$/m);
    if (dateMatch && dateMatch[1]) {
      const dateStr = dateMatch[1].trim().replace(/^["']|["']$/g, '');
      try {
        const parsed = new Date(dateStr);
        if (!isNaN(parsed.getTime())) {
          return parsed.toISOString().split('T')[0];
        }
      } catch (e) {
        // Continue to filename parsing
      }
    }
  }

  if (filePath) {
    const filename = path.basename(filePath);

    // Try YYYY-MM-DD format
    const isoMatch = filename.match(/(\d{4}-\d{2}-\d{2})/);
    if (isoMatch) {
      return isoMatch[1];
    }

    // Try DD-MM-YY format
    const ddmmyyMatch = filename.match(/(\d{2})-(\d{2})-(\d{2})/);
    if (ddmmyyMatch) {
      const [, day, month, year] = ddmmyyMatch;
      const fullYear = parseInt(year) > 50 ? `19${year}` : `20${year}`;
      return `${fullYear}-${month}-${day}`;
    }
  }

  return null;
}

// ───────────────────────────────────────────────────────────────
// EMBEDDING GENERATION WRAPPER
// ───────────────────────────────────────────────────────────────

/**
 * Generate embedding for a query string with error handling
 *
 * Uses the task-specific generateQueryEmbedding from embeddings.js
 * which applies the "search_query: " prefix required by nomic-embed-text-v1.5.
 *
 * Wraps the embeddings module with graceful error handling.
 * Returns null on failure instead of throwing.
 *
 * @param {string} query - Query text to embed
 * @returns {Promise<Float32Array|null>} Embedding vector or null on failure
 */
async function generateQueryEmbedding(query) {
  if (!query || typeof query !== 'string' || query.trim().length === 0) {
    console.warn('[vector-index] Empty query provided for embedding');
    return null;
  }

  try {
    const embeddings = getEmbeddingsModule();
    // Use task-specific function that adds "search_query: " prefix
    const embedding = await embeddings.generateQueryEmbedding(query.trim());
    return embedding;
  } catch (error) {
    console.warn(`[vector-index] Query embedding failed: ${error.message}`);
    return null;
  }
}

// ───────────────────────────────────────────────────────────────
// KEYWORD SEARCH FALLBACK
// ───────────────────────────────────────────────────────────────

/**
 * Fallback keyword search when vector search unavailable
 *
 * Performs case-insensitive substring matching on:
 * - Title
 * - Trigger phrases
 * - Spec folder name
 *
 * @param {string} query - Search query
 * @param {Object} [options] - Search options
 * @param {number} [options.limit=20] - Maximum results
 * @param {string} [options.specFolder] - Filter by spec folder
 * @returns {Object[]} Matched results with basic scoring
 */
function keywordSearch(query, options = {}) {
  const database = initializeDb();
  const { limit = 20, specFolder = null } = options;

  if (!query || typeof query !== 'string') {
    return [];
  }

  const searchTerms = query.toLowerCase().trim().split(/\s+/).filter(t => t.length >= 2);
  if (searchTerms.length === 0) {
    return [];
  }

  // Build WHERE clause
  let whereClause = '1=1';
  const params = [];

  if (specFolder) {
    whereClause += ' AND spec_folder = ?';
    params.push(specFolder);
  }

  // Get all potential matches
  const sql = `
    SELECT * FROM memory_index
    WHERE ${whereClause}
    ORDER BY importance_weight DESC, created_at DESC
  `;

  const rows = database.prepare(sql).all(...params);

  // Score each row based on keyword matches
  const scored = rows.map(row => {
    let score = 0;
    const searchableText = [
      row.title || '',
      row.trigger_phrases || '',
      row.spec_folder || '',
      row.file_path || ''
    ].join(' ').toLowerCase();

    for (const term of searchTerms) {
      if (searchableText.includes(term)) {
        score += 1;

        // Bonus for title match
        if ((row.title || '').toLowerCase().includes(term)) {
          score += 2;
        }

        // Bonus for trigger phrase match
        if ((row.trigger_phrases || '').toLowerCase().includes(term)) {
          score += 1.5;
        }
      }
    }

    // Apply importance weight
    score *= (0.5 + row.importance_weight);

    return { ...row, keyword_score: score };
  });

  // Filter and sort by score
  const filtered = scored
    .filter(row => row.keyword_score > 0)
    .sort((a, b) => b.keyword_score - a.keyword_score)
    .slice(0, limit);

  // Parse trigger_phrases JSON
  return filtered.map(row => {
    if (row.trigger_phrases) {
      try {
        row.trigger_phrases = JSON.parse(row.trigger_phrases);
      } catch (e) {
        row.trigger_phrases = [];
      }
    }
    return row;
  });
}

// ───────────────────────────────────────────────────────────────
// ENRICHED VECTOR SEARCH
// ───────────────────────────────────────────────────────────────

/**
 * Search memories with enriched results including full metadata
 *
 * Returns complete search results with:
 * - Ranked results with similarity scores
 * - Extracted titles and snippets from file content
 * - Tags parsed from content
 * - Date extracted from content/filename
 *
 * Automatically falls back to keyword search if:
 * - sqlite-vec is not available
 * - Embedding generation fails
 *
 * @param {string} query - Search query (natural language)
 * @param {number} [limit=20] - Maximum results
 * @param {Object} [options] - Additional options
 * @param {string} [options.specFolder] - Filter by spec folder
 * @param {number} [options.minSimilarity=30] - Minimum similarity threshold (0-100)
 * @returns {Promise<Array<{
 *   rank: number,
 *   similarity: number,
 *   title: string,
 *   specFolder: string,
 *   filePath: string,
 *   date: string|null,
 *   tags: string[],
 *   snippet: string,
 *   id: number,
 *   importanceWeight: number,
 *   searchMethod: 'vector'|'keyword'
 * }>>} Enriched search results
 */
async function vectorSearchEnriched(query, limit = 20, options = {}) {
  const startTime = Date.now();
  const { specFolder = null, minSimilarity = 30 } = options;

  // Try to generate query embedding
  const queryEmbedding = await generateQueryEmbedding(query);

  let rawResults;
  let searchMethod = 'vector';

  if (queryEmbedding && sqliteVecAvailable) {
    // Use vector search
    rawResults = vectorSearch(queryEmbedding, {
      limit,
      specFolder,
      minSimilarity
    });
  } else {
    // Fallback to keyword search
    console.warn('[vector-index] Falling back to keyword search');
    searchMethod = 'keyword';
    rawResults = keywordSearch(query, { limit, specFolder });
  }

  // Enrich results with content extraction
  const enrichedResults = [];

  for (let i = 0; i < rawResults.length; i++) {
    const row = rawResults[i];

    // Read file content for extraction
    let content = '';
    try {
      if (row.file_path && fs.existsSync(row.file_path)) {
        content = fs.readFileSync(row.file_path, 'utf-8');
      }
    } catch (err) {
      console.warn(`[vector-index] Could not read file ${row.file_path}: ${err.message}`);
    }

    // Extract metadata from content
    const title = row.title || extractTitle(content, row.file_path);
    const snippet = extractSnippet(content);
    const tags = extractTags(content);
    const date = extractDate(content, row.file_path) || row.created_at?.split('T')[0] || null;

    // Calculate similarity score
    let similarity;
    if (searchMethod === 'vector') {
      similarity = row.similarity || 0;
    } else {
      // Normalize keyword score to 0-100 scale
      similarity = Math.min(100, (row.keyword_score || 0) * 20);
    }

    enrichedResults.push({
      rank: i + 1,
      similarity: Math.round(similarity * 100) / 100,
      title,
      specFolder: row.spec_folder,
      filePath: row.file_path,
      date,
      tags,
      snippet,
      id: row.id,
      importanceWeight: row.importance_weight,
      searchMethod
    });
  }

  const elapsed = Date.now() - startTime;
  if (elapsed > 500) {
    console.warn(`[vector-index] Enriched search took ${elapsed}ms (target <500ms)`);
  }

  return enrichedResults;
}

// ───────────────────────────────────────────────────────────────
// MULTI-CONCEPT SEARCH (ENHANCED)
// ───────────────────────────────────────────────────────────────

/**
 * Search with multiple concepts using AND logic
 *
 * Accepts either:
 * - Array of pre-computed embeddings (Float32Array/Buffer)
 * - Array of string concepts (will generate embeddings)
 *
 * Returns memories that match ALL concepts above the threshold.
 *
 * @param {Array<string|Float32Array|Buffer>} concepts - Array of concepts (2-5)
 * @param {number} [limit=20] - Maximum results
 * @param {Object} [options] - Search options
 * @param {string} [options.specFolder] - Filter by spec folder
 * @param {number} [options.minSimilarity=50] - Minimum similarity per concept (0-100)
 * @returns {Promise<Array<{
 *   rank: number,
 *   avgSimilarity: number,
 *   conceptSimilarities: number[],
 *   title: string,
 *   specFolder: string,
 *   filePath: string,
 *   date: string|null,
 *   tags: string[],
 *   snippet: string,
 *   id: number
 * }>>} Results matching ALL concepts with per-concept scores
 */
async function multiConceptSearchEnriched(concepts, limit = 20, options = {}) {
  const startTime = Date.now();

  if (!Array.isArray(concepts) || concepts.length < 2 || concepts.length > 5) {
    throw new Error('Multi-concept search requires 2-5 concepts');
  }

  const { specFolder = null, minSimilarity = 50 } = options;

  // Convert string concepts to embeddings
  const conceptEmbeddings = [];
  for (const concept of concepts) {
    if (typeof concept === 'string') {
      const embedding = await generateQueryEmbedding(concept);
      if (!embedding) {
        console.warn(`[vector-index] Failed to embed concept: "${concept}"`);
        // Fall back to keyword intersection
        return multiConceptKeywordSearch(concepts.filter(c => typeof c === 'string'), limit, options);
      }
      conceptEmbeddings.push(embedding);
    } else {
      // Assume it's already an embedding
      conceptEmbeddings.push(concept);
    }
  }

  // Check if vector search is available
  if (!sqliteVecAvailable) {
    console.warn('[vector-index] Falling back to keyword multi-concept search');
    return multiConceptKeywordSearch(concepts.filter(c => typeof c === 'string'), limit, options);
  }

  // Use existing multiConceptSearch for vector-based search
  const rawResults = multiConceptSearch(conceptEmbeddings, { limit, specFolder, minSimilarity });

  // Enrich results
  const enrichedResults = [];

  for (let i = 0; i < rawResults.length; i++) {
    const row = rawResults[i];

    // Read file content
    let content = '';
    try {
      if (row.file_path && fs.existsSync(row.file_path)) {
        content = fs.readFileSync(row.file_path, 'utf-8');
      }
    } catch (err) {
      // Ignore file read errors
    }

    const title = row.title || extractTitle(content, row.file_path);
    const snippet = extractSnippet(content);
    const tags = extractTags(content);
    const date = extractDate(content, row.file_path) || row.created_at?.split('T')[0] || null;

    enrichedResults.push({
      rank: i + 1,
      avgSimilarity: Math.round((row.avg_similarity || 0) * 100) / 100,
      conceptSimilarities: row.concept_similarities || [],
      title,
      specFolder: row.spec_folder,
      filePath: row.file_path,
      date,
      tags,
      snippet,
      id: row.id,
      importanceWeight: row.importance_weight
    });
  }

  const elapsed = Date.now() - startTime;
  if (elapsed > 500) {
    console.warn(`[vector-index] Multi-concept search took ${elapsed}ms (target <500ms)`);
  }

  return enrichedResults;
}

/**
 * Keyword-based multi-concept search (fallback)
 *
 * Uses intersection of keyword matches for AND logic.
 *
 * @param {string[]} concepts - Array of search terms
 * @param {number} limit - Maximum results
 * @param {Object} options - Search options
 * @returns {Array} Results matching ALL concepts
 */
function multiConceptKeywordSearch(concepts, limit = 20, options = {}) {
  const database = initializeDb();
  const { specFolder = null } = options;

  if (!concepts.length) return [];

  // Get keyword results for each concept
  const conceptResults = concepts.map(concept =>
    keywordSearch(concept, { limit: 100, specFolder })
  );

  // Find intersection - memories that appear in ALL concept results
  const idCounts = new Map();
  const idToRow = new Map();

  for (const results of conceptResults) {
    for (const row of results) {
      const count = idCounts.get(row.id) || 0;
      idCounts.set(row.id, count + 1);
      if (!idToRow.has(row.id)) {
        idToRow.set(row.id, row);
      }
    }
  }

  // Filter to only those appearing in all concept results
  const matchingIds = [];
  for (const [id, count] of idCounts) {
    if (count === concepts.length) {
      matchingIds.push(id);
    }
  }

  // Build enriched results
  const enrichedResults = [];
  for (let i = 0; i < Math.min(matchingIds.length, limit); i++) {
    const id = matchingIds[i];
    const row = idToRow.get(id);

    let content = '';
    try {
      if (row.file_path && fs.existsSync(row.file_path)) {
        content = fs.readFileSync(row.file_path, 'utf-8');
      }
    } catch (err) {
      // Ignore
    }

    const title = row.title || extractTitle(content, row.file_path);
    const snippet = extractSnippet(content);
    const tags = extractTags(content);
    const date = extractDate(content, row.file_path) || row.created_at?.split('T')[0] || null;

    enrichedResults.push({
      rank: i + 1,
      avgSimilarity: Math.min(100, (row.keyword_score || 1) * 15),
      conceptSimilarities: concepts.map(() => row.keyword_score || 1),
      title,
      specFolder: row.spec_folder,
      filePath: row.file_path,
      date,
      tags,
      snippet,
      id: row.id,
      importanceWeight: row.importance_weight,
      searchMethod: 'keyword'
    });
  }

  return enrichedResults;
}

/**
 * Parse quoted terms from a search query
 *
 * Extracts multiple quoted terms for AND search.
 * Example: '"memory system" "vector search"' => ['memory system', 'vector search']
 *
 * @param {string} query - Search query with quoted terms
 * @returns {string[]} Array of extracted terms
 */
function parseQuotedTerms(query) {
  if (!query || typeof query !== 'string') {
    return [];
  }

  const quoted = [];
  const regex = /"([^"]+)"/g;
  let match;

  while ((match = regex.exec(query)) !== null) {
    if (match[1] && match[1].trim()) {
      quoted.push(match[1].trim());
    }
  }

  return quoted;
}

// ───────────────────────────────────────────────────────────────
// SMART RANKING AND DIVERSITY (T3.5, T3.6, T3.7)
// ───────────────────────────────────────────────────────────────

/**
 * Apply smart ranking to search results
 *
 * Re-ranks results based on a composite score combining:
 * - Similarity: 50% weight (semantic relevance)
 * - Recency: 30% weight (newer = higher)
 * - Usage: 20% weight (more accessed = higher)
 *
 * This is "invisible magic" - users experience better results
 * without knowing the mechanism.
 *
 * @param {Array} results - Raw search results with similarity scores
 * @returns {Array} Re-ranked results with composite smartScore
 */
function applySmartRanking(results) {
  if (!results || results.length === 0) return results;

  const now = Date.now();
  const WEEK = 7 * 24 * 60 * 60 * 1000;
  const MONTH = 30 * 24 * 60 * 60 * 1000;

  return results.map(r => {
    // Calculate recency factor based on created_at
    const createdAt = r.created_at ? new Date(r.created_at).getTime() : now;
    const age = now - createdAt;
    let recencyFactor;
    if (age < WEEK) {
      recencyFactor = 1.0;  // Full boost for last week
    } else if (age < MONTH) {
      recencyFactor = 0.8;  // 80% for last month
    } else {
      recencyFactor = 0.5;  // 50% for older
    }

    // Calculate usage factor (capped at 10 accesses for normalization)
    const usageFactor = Math.min(1.0, (r.access_count || 0) / 10);

    // Normalize similarity to 0-1 (it comes as 0-100)
    const similarityFactor = (r.similarity || 0) / 100;

    // Composite score: 50% similarity, 30% recency, 20% usage
    r.smartScore = (similarityFactor * 0.5) + (recencyFactor * 0.3) + (usageFactor * 0.2);
    r.smartScore = Math.round(r.smartScore * 100) / 100;  // Round to 2 decimals

    return r;
  }).sort((a, b) => b.smartScore - a.smartScore);
}

/**
 * Apply diversity filtering using MMR (Maximal Marginal Relevance)
 *
 * Reduces redundancy in search results by penalizing items that are
 * too similar to already-selected items. Uses spec folder and date
 * as proxies for content similarity.
 *
 * MMR formula: score = relevance - lambda * maxSimilarityToSelected
 *
 * @param {Array} results - Search results (should have smartScore or similarity)
 * @param {number} [diversityFactor=0.3] - Lambda: how much to penalize similarity (0-1)
 * @returns {Array} Diversified results maintaining relevance
 */
function applyDiversity(results, diversityFactor = 0.3) {
  if (!results || results.length <= 3) return results;  // Don't diversify tiny result sets

  const selected = [results[0]];  // Always include top result
  const remaining = [...results.slice(1)];

  while (selected.length < results.length && remaining.length > 0) {
    let bestIdx = 0;
    let bestScore = -Infinity;

    for (let i = 0; i < remaining.length; i++) {
      const candidate = remaining[i];
      const relevance = candidate.smartScore || (candidate.similarity / 100) || 0;

      // Find max similarity to already selected items
      // Use spec folder and date as proxies for similarity
      let maxSimilarityToSelected = 0;
      for (const sel of selected) {
        // Same spec folder = high similarity (likely related content)
        if (sel.specFolder === candidate.specFolder || sel.spec_folder === candidate.spec_folder) {
          maxSimilarityToSelected = Math.max(maxSimilarityToSelected, 0.8);
        }
        // Same date = moderate similarity (likely same session)
        if (sel.date === candidate.date) {
          maxSimilarityToSelected = Math.max(maxSimilarityToSelected, 0.5);
        }
      }

      // MMR score: relevance - lambda * maxSimilarity
      const mmrScore = relevance - (diversityFactor * maxSimilarityToSelected);

      if (mmrScore > bestScore) {
        bestScore = mmrScore;
        bestIdx = i;
      }
    }

    selected.push(remaining.splice(bestIdx, 1)[0]);
  }

  return selected;
}

/**
 * Learn trigger phrases from user search behavior
 *
 * Called when user selects a search result. Extracts meaningful
 * terms from the search query and adds them as trigger phrases
 * for future searches.
 *
 * Learning rules:
 * - Terms must be at least 4 characters
 * - Common stop words are excluded
 * - Max 3 new triggers per search
 * - Max 10 total triggers per memory
 *
 * @param {string} searchQuery - The query user searched for
 * @param {number} selectedMemoryId - ID of the memory user selected
 * @returns {boolean} True if triggers were updated
 */
function learnFromSelection(searchQuery, selectedMemoryId) {
  if (!searchQuery || !selectedMemoryId) return false;

  const database = initializeDb();

  // Get current triggers
  let memory;
  try {
    memory = database.prepare(
      'SELECT trigger_phrases FROM memory_index WHERE id = ?'
    ).get(selectedMemoryId);
  } catch (e) {
    console.warn(`[vector-index] learnFromSelection query error: ${e.message}`);
    return false;
  }

  if (!memory) return false;

  let existing = [];
  try {
    existing = JSON.parse(memory.trigger_phrases || '[]');
  } catch (e) {
    existing = [];
  }

  // Stop words to exclude from learning
  const stopWords = [
    'that', 'this', 'what', 'where', 'when', 'which', 'with', 'from',
    'have', 'been', 'were', 'being', 'about', 'into', 'through', 'during',
    'before', 'after', 'above', 'below', 'between', 'under', 'again',
    'further', 'then', 'once', 'here', 'there', 'each', 'some', 'other'
  ];

  // Extract meaningful terms from query
  const newTerms = searchQuery
    .toLowerCase()
    .split(/\s+/)
    .filter(term => {
      // Must be at least 4 chars
      if (term.length < 4) return false;
      // Skip common words
      if (stopWords.includes(term)) return false;
      // Skip if already exists (case-insensitive)
      if (existing.some(e => e.toLowerCase() === term)) return false;
      // Skip pure numbers
      if (/^\d+$/.test(term)) return false;
      return true;
    })
    .slice(0, 3);  // Max 3 new triggers per search

  if (newTerms.length === 0) return false;

  // Cap total triggers at 10 per memory
  const updated = [...existing, ...newTerms].slice(0, 10);

  try {
    database.prepare(
      'UPDATE memory_index SET trigger_phrases = ? WHERE id = ?'
    ).run(JSON.stringify(updated), selectedMemoryId);
    return true;
  } catch (e) {
    console.warn(`[vector-index] learnFromSelection update error: ${e.message}`);
    return false;
  }
}

/**
 * Enhanced search with smart ranking and diversity
 *
 * Wraps vectorSearchEnriched with additional processing:
 * 1. Fetches more results than requested (2x limit)
 * 2. Applies smart ranking (similarity + recency + usage)
 * 3. Applies diversity filtering (MMR algorithm)
 * 4. Trims to requested limit
 *
 * @param {string} query - Search query
 * @param {number} [limit=20] - Max results to return
 * @param {Object} [options] - Search options
 * @param {string} [options.specFolder] - Filter by spec folder
 * @param {number} [options.minSimilarity=30] - Minimum similarity threshold
 * @param {boolean} [options.noDiversity=false] - Skip diversity filtering
 * @param {number} [options.diversityFactor=0.3] - MMR lambda (0-1)
 * @returns {Promise<Array>} Enhanced search results with smartScore
 */
async function enhancedSearch(query, limit = 20, options = {}) {
  const startTime = Date.now();

  // Get more results than needed for diversity filtering
  const fetchLimit = Math.min(limit * 2, 100);

  // Get base results
  const results = await vectorSearchEnriched(query, fetchLimit, {
    specFolder: options.specFolder,
    minSimilarity: options.minSimilarity || 30
  });

  // Apply smart ranking
  const ranked = applySmartRanking(results);

  // Apply diversity (optional, default on)
  const diversityFactor = options.diversityFactor !== undefined ? options.diversityFactor : 0.3;
  const diverse = options.noDiversity ? ranked : applyDiversity(ranked, diversityFactor);

  // Trim to requested limit
  const finalResults = diverse.slice(0, limit);

  const elapsed = Date.now() - startTime;
  if (elapsed > 600) {
    console.warn(`[vector-index] Enhanced search took ${elapsed}ms (target <600ms)`);
  }

  return finalResults;
}

// ───────────────────────────────────────────────────────────────
// RELATED MEMORIES & USAGE TRACKING (Phase 1 & 3)
// ───────────────────────────────────────────────────────────────

/**
 * LRU Cache for search queries
 * Simple Map-based implementation without external dependencies
 */
let queryCache = null;

/**
 * Get or initialize the query cache
 * Uses a simple Map with manual LRU eviction
 *
 * @returns {Map} LRU cache instance with maxSize and ttl properties
 */
function getQueryCache() {
  if (!queryCache) {
    queryCache = new Map();
    queryCache.maxSize = 500;
    queryCache.ttl = 15 * 60 * 1000; // 15 minutes
  }
  return queryCache;
}

/**
 * Find and link related memories when saving a new memory (T1.3)
 *
 * Automatically discovers semantically similar memories using vector search
 * and stores their IDs with similarity scores in the related_memories field.
 *
 * @param {number} newMemoryId - ID of the newly saved memory
 * @param {string} content - Content of the memory (for embedding generation)
 * @returns {Promise<void>}
 *
 * @example
 * // After indexing a new memory
 * const memoryId = indexMemory({ specFolder, filePath, embedding, ... });
 * await linkRelatedOnSave(memoryId, fileContent);
 */
async function linkRelatedOnSave(newMemoryId, content) {
  if (!content || typeof content !== 'string' || content.trim().length === 0) {
    return;
  }

  try {
    // Generate embedding for the content (first 1000 chars for efficiency)
    const embedding = await generateQueryEmbedding(content.substring(0, 1000));
    if (!embedding) {
      console.warn(`[vector-index] Could not generate embedding for memory ${newMemoryId}`);
      return;
    }

    // Find similar memories (75% threshold as specified)
    const similar = vectorSearch(embedding, {
      limit: 6,  // Get 6 to allow for filtering out self
      minSimilarity: 75
    });

    // Filter out self and limit to 5 related memories
    const related = similar
      .filter(r => r.id !== newMemoryId)
      .slice(0, 5)
      .map(r => ({ id: r.id, similarity: r.similarity }));

    if (related.length > 0) {
      const database = initializeDb();
      database.prepare(`
        UPDATE memory_index
        SET related_memories = ?
        WHERE id = ?
      `).run(JSON.stringify(related), newMemoryId);
    }
  } catch (error) {
    console.warn(`[vector-index] Failed to link related memories for ${newMemoryId}: ${error.message}`);
  }
}

/**
 * Record that a memory was accessed for usage tracking (T3.2)
 *
 * Increments access_count and updates last_accessed_at timestamp.
 * Used for analytics and potential cleanup of rarely-accessed memories.
 *
 * @param {number} memoryId - ID of the accessed memory
 * @returns {boolean} True if access was recorded, false if memory not found
 *
 * @example
 * // When displaying a memory to the user
 * recordAccess(memory.id);
 */
function recordAccess(memoryId) {
  try {
    const database = initializeDb();
    const now = new Date().toISOString();

    const result = database.prepare(`
      UPDATE memory_index
      SET access_count = access_count + 1,
          last_accessed_at = ?
      WHERE id = ?
    `).run(now, memoryId);

    return result.changes > 0;
  } catch (error) {
    console.warn(`[vector-index] Failed to record access for memory ${memoryId}: ${error.message}`);
    return false;
  }
}

/**
 * Cached version of vectorSearchEnriched (T3.4)
 *
 * Wraps vectorSearchEnriched with a simple LRU cache to avoid
 * repeated embedding generation and database queries for identical searches.
 *
 * Cache settings:
 * - Max entries: 500
 * - TTL: 15 minutes
 * - Key format: query:limit:JSON(options)
 *
 * @param {string} query - Search query (natural language)
 * @param {number} [limit=20] - Maximum results
 * @param {Object} [options] - Search options (specFolder, minSimilarity)
 * @returns {Promise<Array>} Cached or fresh search results
 *
 * @example
 * // Use instead of vectorSearchEnriched for repeated queries
 * const results = await cachedSearch('authentication flow', 10);
 */
async function cachedSearch(query, limit = 20, options = {}) {
  const cache = getQueryCache();
  const key = `${query}:${limit}:${JSON.stringify(options)}`;

  // Check cache for valid entry
  const cached = cache.get(key);
  if (cached && (Date.now() - cached.timestamp < cache.ttl)) {
    return cached.results;
  }

  // Perform actual search
  const results = await vectorSearchEnriched(query, limit, options);

  // Simple LRU eviction: delete oldest entry if at max size
  if (cache.size >= cache.maxSize) {
    const oldest = cache.keys().next().value;
    cache.delete(oldest);
  }

  // Store in cache with timestamp
  cache.set(key, { results, timestamp: Date.now() });

  return results;
}

/**
 * Clear the search cache
 *
 * Use when memories are updated/deleted to ensure fresh results.
 *
 * @returns {void}
 *
 * @example
 * // After modifying memories
 * deleteMemory(id);
 * clearSearchCache();
 */
function clearSearchCache() {
  if (queryCache) {
    queryCache.clear();
  }
}

/**
 * Get related memories for a given memory ID (T1.3 helper)
 *
 * Retrieves the pre-computed related memories stored during save,
 * with full metadata for each related memory.
 *
 * @param {number} memoryId - Memory ID to get related memories for
 * @returns {Array<Object>} Related memories with metadata and relationSimilarity
 *
 * @example
 * const related = getRelatedMemories(currentMemory.id);
 * // Returns: [{ id, title, specFolder, ..., relationSimilarity: 82.5 }, ...]
 */
function getRelatedMemories(memoryId) {
  try {
    const database = initializeDb();

    const memory = database.prepare(`
      SELECT related_memories FROM memory_index WHERE id = ?
    `).get(memoryId);

    if (!memory || !memory.related_memories) {
      return [];
    }

    const related = JSON.parse(memory.related_memories);

    // Fetch full metadata for each related memory
    return related.map(rel => {
      const fullMemory = getMemory(rel.id);
      if (fullMemory) {
        return {
          ...fullMemory,
          relationSimilarity: rel.similarity
        };
      }
      return null;
    }).filter(Boolean);
  } catch (error) {
    console.warn(`[vector-index] Failed to get related memories for ${memoryId}: ${error.message}`);
    return [];
  }
}

/**
 * Get usage statistics for memories (T3.2 analytics helper)
 *
 * Returns memories sorted by access count or last accessed time.
 * Useful for identifying frequently used vs stale memories.
 *
 * @param {Object} [options] - Query options
 * @param {string} [options.sortBy='access_count'] - Sort by 'access_count' or 'last_accessed_at'
 * @param {string} [options.order='DESC'] - Sort order 'ASC' or 'DESC'
 * @param {number} [options.limit=20] - Maximum results
 * @returns {Array<Object>} Memories with usage stats
 */
function getUsageStats(options = {}) {
  const {
    sortBy = 'access_count',
    order = 'DESC',
    limit = 20
  } = options;

  // Validate sortBy to prevent SQL injection
  const validSortFields = ['access_count', 'last_accessed_at', 'confidence'];
  const sortField = validSortFields.includes(sortBy) ? sortBy : 'access_count';
  const sortOrder = order.toUpperCase() === 'ASC' ? 'ASC' : 'DESC';

  const database = initializeDb();

  const rows = database.prepare(`
    SELECT id, title, spec_folder, file_path, access_count,
           last_accessed_at, confidence, created_at
    FROM memory_index
    WHERE access_count > 0
    ORDER BY ${sortField} ${sortOrder}
    LIMIT ?
  `).all(limit);

  return rows;
}

/**
 * Update confidence score for a memory
 *
 * @param {number} memoryId - Memory ID to update
 * @param {number} confidence - New confidence score (0.0 to 1.0)
 * @returns {boolean} True if updated successfully
 */
function updateConfidence(memoryId, confidence) {
  if (typeof confidence !== 'number' || confidence < 0 || confidence > 1) {
    console.warn(`[vector-index] Invalid confidence value: ${confidence}`);
    return false;
  }

  try {
    const database = initializeDb();
    const result = database.prepare(`
      UPDATE memory_index
      SET confidence = ?
      WHERE id = ?
    `).run(confidence, memoryId);

    return result.changes > 0;
  } catch (error) {
    console.warn(`[vector-index] Failed to update confidence for ${memoryId}: ${error.message}`);
    return false;
  }
}

// ───────────────────────────────────────────────────────────────
// CLEANUP FUNCTIONS (T2.2)
// ───────────────────────────────────────────────────────────────

/**
 * Find memories that may be candidates for cleanup
 * Uses smart defaults - users don't configure this
 *
 * Smart defaults (internal):
 * - maxAgeDays: 90 (older than 3 months)
 * - maxAccessCount: 2 (accessed less than 3 times)
 * - maxConfidence: 0.4 (low importance score)
 *
 * A memory is a candidate if it meets ANY of these criteria
 *
 * @param {Object} options - Override defaults for testing
 * @param {number} options.maxAgeDays - Max age in days (default: 90)
 * @param {number} options.maxAccessCount - Max access count (default: 2)
 * @param {number} options.maxConfidence - Max confidence (default: 0.4)
 * @param {number} options.limit - Max candidates to return (default: 50)
 * @returns {Array<Object>} Cleanup candidates with metadata
 */
function findCleanupCandidates(options = {}) {
  const database = initializeDb();

  const {
    maxAgeDays = 90,
    maxAccessCount = 2,
    maxConfidence = 0.4,
    limit = 50
  } = options;

  // Calculate cutoff date
  const cutoffDate = new Date();
  cutoffDate.setDate(cutoffDate.getDate() - maxAgeDays);
  const cutoffIso = cutoffDate.toISOString();

  // Query for candidates - meeting ANY criteria
  const sql = `
    SELECT
      id,
      spec_folder,
      file_path,
      title,
      created_at,
      last_accessed_at,
      access_count,
      confidence,
      importance_weight
    FROM memory_index
    WHERE
      created_at < ?
      OR access_count <= ?
      OR confidence <= ?
      OR (last_accessed_at IS NULL AND created_at < ?)
    ORDER BY
      last_accessed_at ASC NULLS FIRST,
      access_count ASC,
      confidence ASC
    LIMIT ?
  `;

  let rows;
  try {
    rows = database.prepare(sql).all(
      cutoffIso,
      maxAccessCount,
      maxConfidence,
      cutoffIso,
      limit
    );
  } catch (e) {
    console.warn(`[vector-index] findCleanupCandidates error: ${e.message}`);
    return [];
  }

  // Helper function to format age strings
  function formatAgeString(dateString) {
    if (!dateString) return 'never';

    const date = new Date(dateString);
    const now = Date.now();
    const ageMs = now - date.getTime();
    const ageDays = Math.floor(ageMs / (24 * 60 * 60 * 1000));

    if (ageDays < 1) {
      return 'today';
    } else if (ageDays === 1) {
      return 'yesterday';
    } else if (ageDays < 7) {
      return `${ageDays} days ago`;
    } else if (ageDays < 30) {
      const weeks = Math.floor(ageDays / 7);
      return `${weeks} week${weeks > 1 ? 's' : ''} ago`;
    } else {
      const months = Math.floor(ageDays / 30);
      return `${months} month${months > 1 ? 's' : ''} ago`;
    }
  }

  // Enrich with human-readable age
  return rows.map(row => {
    const ageString = formatAgeString(row.created_at);
    const lastAccessString = formatAgeString(row.last_accessed_at);

    // Determine why this is a candidate
    const reasons = [];
    if (row.created_at && new Date(row.created_at) < cutoffDate) {
      reasons.push(`created ${ageString}`);
    }
    if ((row.access_count || 0) <= maxAccessCount) {
      const count = row.access_count || 0;
      reasons.push(`accessed ${count} time${count !== 1 ? 's' : ''}`);
    }
    if ((row.confidence || 0.5) <= maxConfidence) {
      reasons.push(`low importance (${Math.round((row.confidence || 0.5) * 100)}%)`);
    }

    return {
      id: row.id,
      specFolder: row.spec_folder,
      filePath: row.file_path,
      title: row.title || 'Untitled',
      createdAt: row.created_at,
      lastAccessedAt: row.last_accessed_at,
      accessCount: row.access_count || 0,
      confidence: row.confidence || 0.5,
      ageString,
      lastAccessString,
      reasons
    };
  });
}

/**
 * Delete multiple memories by ID
 * Used by cleanup command for batch operations
 *
 * @param {number[]} memoryIds - Array of memory IDs to delete
 * @returns {Object} Result with counts
 */
function deleteMemories(memoryIds) {
  if (!memoryIds || memoryIds.length === 0) {
    return { deleted: 0, failed: 0 };
  }

  const database = initializeDb();
  let deleted = 0;
  let failed = 0;

  const deleteTransaction = database.transaction(() => {
    for (const id of memoryIds) {
      try {
        // Delete from vec_memories first (if it exists and sqlite-vec is available)
        if (sqliteVecAvailable) {
          try {
            database.prepare('DELETE FROM vec_memories WHERE rowid = ?').run(BigInt(id));
          } catch (vecError) {
            // Vector table might not have this entry - continue with metadata delete
          }
        }

        // Delete from memory_index
        const result = database.prepare('DELETE FROM memory_index WHERE id = ?').run(id);
        if (result.changes > 0) {
          deleted++;
        } else {
          failed++;
        }
      } catch (e) {
        console.warn(`[vector-index] Failed to delete memory ${id}: ${e.message}`);
        failed++;
      }
    }
  });

  try {
    deleteTransaction();
  } catch (e) {
    console.warn(`[vector-index] deleteMemories transaction error: ${e.message}`);
  }

  return { deleted, failed };
}

/**
 * Get a preview of memory content for the cleanup [v]iew option
 *
 * @param {number} memoryId - Memory ID
 * @param {number} maxLines - Maximum lines to return (default: 50)
 * @returns {Object|null} Memory preview with content
 */
function getMemoryPreview(memoryId, maxLines = 50) {
  const database = initializeDb();

  let memory;
  try {
    memory = database.prepare(`
      SELECT * FROM memory_index WHERE id = ?
    `).get(memoryId);
  } catch (e) {
    console.warn(`[vector-index] getMemoryPreview query error: ${e.message}`);
    return null;
  }

  if (!memory) return null;

  let content = '';
  try {
    if (memory.file_path && fs.existsSync(memory.file_path)) {
      const fullContent = fs.readFileSync(memory.file_path, 'utf-8');
      const lines = fullContent.split('\n');
      content = lines.slice(0, maxLines).join('\n');
      if (lines.length > maxLines) {
        content += `\n... (${lines.length - maxLines} more lines)`;
      }
    }
  } catch (e) {
    content = '(Unable to read file content)';
  }

  // Helper function to format age strings (reused from findCleanupCandidates)
  function formatAgeString(dateString) {
    if (!dateString) return 'never';

    const date = new Date(dateString);
    const now = Date.now();
    const ageMs = now - date.getTime();
    const ageDays = Math.floor(ageMs / (24 * 60 * 60 * 1000));

    if (ageDays < 1) {
      return 'today';
    } else if (ageDays === 1) {
      return 'yesterday';
    } else if (ageDays < 7) {
      return `${ageDays} days ago`;
    } else if (ageDays < 30) {
      const weeks = Math.floor(ageDays / 7);
      return `${weeks} week${weeks > 1 ? 's' : ''} ago`;
    } else {
      const months = Math.floor(ageDays / 30);
      return `${months} month${months > 1 ? 's' : ''} ago`;
    }
  }

  return {
    id: memory.id,
    specFolder: memory.spec_folder,
    filePath: memory.file_path,
    title: memory.title || 'Untitled',
    createdAt: memory.created_at,
    lastAccessedAt: memory.last_accessed_at,
    accessCount: memory.access_count || 0,
    confidence: memory.confidence || 0.5,
    ageString: formatAgeString(memory.created_at),
    lastAccessString: formatAgeString(memory.last_accessed_at),
    content
  };
}

// ───────────────────────────────────────────────────────────────
// DATABASE UTILITIES
// ───────────────────────────────────────────────────────────────

/**
 * Close database connection
 */
function closeDb() {
  if (db) {
    db.close();
    db = null;
  }
}

/**
 * Get database path
 * @returns {string} Current database path
 */
function getDbPath() {
  return dbPath;
}

/**
 * Get raw database instance (for advanced queries)
 * @returns {Object} better-sqlite3 instance
 */
function getDb() {
  return initializeDb();
}

/**
 * Verify database integrity
 *
 * @returns {Object} Integrity check results
 */
function verifyIntegrity() {
  const database = initializeDb();

  // Count mismatched rowids
  const orphanedVectors = database.prepare(`
    SELECT COUNT(*) as count FROM vec_memories v
    WHERE NOT EXISTS (SELECT 1 FROM memory_index m WHERE m.id = v.rowid)
  `).get().count;

  const missingVectors = database.prepare(`
    SELECT COUNT(*) as count FROM memory_index m
    WHERE m.embedding_status = 'success'
    AND NOT EXISTS (SELECT 1 FROM vec_memories v WHERE v.rowid = m.id)
  `).get().count;

  const totalMemories = database.prepare('SELECT COUNT(*) as count FROM memory_index').get().count;
  const totalVectors = database.prepare('SELECT COUNT(*) as count FROM vec_memories').get().count;

  return {
    totalMemories,
    totalVectors,
    orphanedVectors,
    missingVectors,
    isConsistent: orphanedVectors === 0 && missingVectors === 0
  };
}

// ───────────────────────────────────────────────────────────────
// MODULE EXPORTS
// ───────────────────────────────────────────────────────────────

/**
 * Check if vector search is available (sqlite-vec loaded)
 * @returns {boolean} True if vector search is available
 */
function isVectorSearchAvailable() {
  return sqliteVecAvailable;
}

module.exports = {
  // Initialization
  initializeDb,
  closeDb,
  getDb,
  getDbPath,

  // Core operations
  indexMemory,
  updateMemory,
  deleteMemory,
  deleteMemoryByPath,

  // Queries
  getMemory,
  getMemoriesByFolder,
  getMemoryCount,
  getStatusCounts,
  getStats,
  verifyIntegrity,

  // Search - Basic
  vectorSearch,
  multiConceptSearch,
  isVectorSearchAvailable,

  // Search - Enriched (US1, US8)
  vectorSearchEnriched,
  multiConceptSearchEnriched,
  keywordSearch,
  multiConceptKeywordSearch,

  // Search - Cached (T3.4)
  cachedSearch,
  clearSearchCache,

  // Smart Ranking & Diversity (T3.5, T3.6, T3.7)
  applySmartRanking,
  applyDiversity,
  learnFromSelection,
  enhancedSearch,

  // Related Memories (T1.3)
  linkRelatedOnSave,
  getRelatedMemories,

  // Usage Tracking (T3.2)
  recordAccess,
  getUsageStats,
  updateConfidence,

  // Cleanup Functions (T2.2)
  findCleanupCandidates,
  deleteMemories,
  getMemoryPreview,

  // Content Extraction Helpers
  extractTitle,
  extractSnippet,
  extractTags,
  extractDate,

  // Query Utilities
  generateQueryEmbedding,
  parseQuotedTerms,

  // Constants
  EMBEDDING_DIM,
  DEFAULT_DB_PATH
};
